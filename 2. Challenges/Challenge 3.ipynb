{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of this challenge you will get familar with the basic concepts of [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/). Relevant links will provided in the Notebook and help you to solve the tasks.\n",
    "\n",
    "Generally a very good source of information is the [Python SDK reference](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py) for Azure Machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Azure ML Python Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Authentication and initializing Azure Machine Learning Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step you have to authenticate against the Azure [Machine Learning Workspace](https://ml.azure.com/). This can be achieved in different ways:\n",
    "\n",
    "1. **Interactive Login Authentication:** The interactive authentication is suitable for local experimentation on your own computer.\n",
    "2. **Azure CLI Authentication:** Azure CLI authentication is suitable if you are already using Azure CLI for managing Azure resources, and want to sign in only once.\n",
    "3. **Managed Service Identity (MSI) Authentication:** The MSI authentication is suitable for automated workflows, for example as part of Azure Devops build.\n",
    "4. **Service Principal Authentication:** The Service Principal authentication is suitable for automated workflows, for example as part of Azure Devops build.\n",
    "\n",
    "For now, we will use the interactive authentication, which is the default mode when using Azure ML SDK. When you connect to your workspace using `Workspace.from_config`, you will get an interactive login dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the user you're authenticated as must have access to the subscription and resource group. If you receive an error\n",
    "```\n",
    "AuthenticationException: You don't have access to xxxxxx-xxxx-xxx-xxx-xxxxxxxxxx subscription. All the subscriptions that you have access to = ...\n",
    "```\n",
    "check that the you used correct login and entered the correct subscription ID.\n",
    "\n",
    "Alternatively, you can also specify the details of your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Alternative login method\n",
    "\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "\n",
    "ws = Workspace(subscription_id='<your-subscription-id>',\n",
    "               resource_group='<your-resource-group-name>',\n",
    "               workspace_name='<your-workspace-name>',\n",
    "               auth=interactive_auth)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we logged in, we can print the Worspace details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Print the workspace details below. See here for the workspace object reference: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Workspace name: \" + ws.name, \n",
    "      \"Azure region: \" + ws.location, \n",
    "      \"Subscription id: \" + ws.subscription_id, \n",
    "      \"Resource group: \" + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload and register data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every workspace comes with a default [datastore](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data) (and you can register more) which is backed by the Azure blob storage account associated with the workspace. We can use it to transfer data from local to the cloud, and create Dataset from it. We will now upload the Iris data to the default datastore (blob) within your workspace.\n",
    "\n",
    "By creating a dataset, you create a reference to the data source location. If you applied any subsetting transformations to the dataset, they will be stored in the dataset as well. The data remains in its existing location, so no extra storage cost is incurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all datastores registered in the current workspace\n",
    "datastores = ws.datastores\n",
    "for name, datastore in datastores.items():\n",
    "    print(name, datastore.datastore_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this challenge we will use the [default datastore](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-access-data#get-datastores-from-your-workspace) that comes with the Azure Machine Learning Workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Retrieve the default datastore for this workspace.\n",
    "\n",
    "Hint: Same link as in the previous hint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default datastore\n",
    "datastore = ws.get_default_datastore()\n",
    "print(datastore.name, datastore.datastore_type, datastore.account_name, datastore.container_name, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Upload the file `./train-dataset/iris.csv` to the target path `train-dataset/tabular/` on the default datastore.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.azure_storage_datastore.azureblobdatastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datastore.upload(src_dir = os.path.join('.', 'train_dataset'),\n",
    "                 target_path = 'train_dataset/image_dataset',\n",
    "                 overwrite = True,\n",
    "                 show_progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will register a dataset in the Azure Machine Learning Workspace as a file dataset. A file dataset can be mounted to the compute engine. When you mount a file system, you attach that file system to a directory (mount point) and make it available to the system. Because mounting load files at the time of processing, it is usually faster than download.\n",
    "Note: mounting is only available for Linux-based compute (DSVM/VM, AMLCompute, HDInsights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "file_dataset = Dataset.File.from_files(path = [(datastore, 'train_dataset/image_dataset/hymenoptera_data')])\n",
    "file_dataset = file_dataset.register(workspace=ws,\n",
    "                                     name='hymenoptera_data',\n",
    "                                     description='hymenoptera training dataset',\n",
    "                                     create_new_version = True)\n",
    "\n",
    "file_dataset.to_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Compute Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample, we want to train a simple scikit-learn model on a remote compute engine on Azure. To do so, we first must create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target).\n",
    "\n",
    "In this challenge, we want to use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource. Once this is created, you are ready to train on your remote compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TASK:** Create a machine learning compute target.\n",
    "\n",
    "Create an Azure Machine Learning Compute cluster and folow the steps one to four.\n",
    "1. Check whether the cluster with the given name already exists.\n",
    "2. Create the configuration (this step is local and only takes a second). Use the SKU `STANDARD_D2_V2` and a maximum of 4 nodes.\n",
    "3. Create the cluster (this step will take about 20 seconds)\n",
    "4. Provision the VMs to bring the cluster to the initial size. This step will take about 3-5 minutes and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.computetarget?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a project directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER_NAME = 'train'\n",
    "TRAIN_FILE_NAME = 'train.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a training script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will need to create your training scripts in your project folder. This will be done in the next step. In practice, you should be able to take any custom training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "If you would like to use Azure ML's [tracking and metrics](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#metrics) capabilities, you will have to add a small amount of Azure ML code inside your training script.\n",
    "\n",
    "In `train_iris.py`, we will log some metrics to our Azure ML run. To do so, we will access the Azure ML Run object within the script:\n",
    "\n",
    "```python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "\n",
    "Further within `train_iris.py`, we log the kernel and penalty parameters, and the highest accuracy the model achieves:\n",
    "\n",
    "```python\n",
    "run.log('Kernel type', np.string(args.kernel))\n",
    "run.log('Penalty', np.float(args.penalty))\n",
    "\n",
    "run.log('Accuracy', np.float(accuracy))\n",
    "```\n",
    "\n",
    "These run metrics will become particularly important when we begin hyperparameter tuning our model in the \"Tune model hyperparameters\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: The training script below misses to log a few of the metrics. Find the `???` and complete the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://pytorch.org/docs/stable/torchvision/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $TRAIN_FOLDER_NAME/$TRAIN_FILE_NAME\n",
    "\n",
    "# Sample from torchvision references: https://github.com/pytorch/vision/tree/master/references/classification\n",
    "\n",
    "from __future__ import print_function\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import onnx\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from azureml.core import Dataset, Run\n",
    "run = Run.get_context() # get the Azure ML run object\n",
    "\n",
    "import utils\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "except ImportError:\n",
    "    amp = None\n",
    "\n",
    "\n",
    "def train_one_epoch(model, criterion, optimizer, data_loader, device, epoch, print_freq, apex=False):\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value}'))\n",
    "    metric_logger.add_meter('img/s', utils.SmoothedValue(window_size=10, fmt='{value}'))\n",
    "\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        start_time = time.time()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "        batch_size = image.shape[0]\n",
    "        metric_logger.update(loss=loss.item(), lr=optimizer.param_groups[0][\"lr\"])\n",
    "        metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "        metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "        metric_logger.meters['img/s'].update(batch_size / (time.time() - start_time))\n",
    "        \n",
    "        # Log metrics in Azure ML\n",
    "        run.log('train_loss', loss.item())\n",
    "        run.log('train_acc1', acc1.item())\n",
    "        run.log('train_acc5', acc5.item())\n",
    "        run.log('train_img/s', batch_size / (time.time() - start_time))\n",
    "        \n",
    "        #run.log('train_loss_{0}'.format(epoch), loss.item())\n",
    "        #run.log('train_acc1_{0}'.format(epoch), acc1.item())\n",
    "        #run.log('train_acc5_{0}'.format(epoch), acc5.item())\n",
    "        #run.log('train_img/s_{0}'.format(epoch), batch_size / (time.time() - start_time))\n",
    "    \n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "\n",
    "    print(' * Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f}'\n",
    "          .format(top1=metric_logger.acc1, top5=metric_logger.acc5))\n",
    "    \n",
    "    # Log metrics in Azure ML\n",
    "    run.log('train_acc1_ga', metric_logger.acc1.global_avg)\n",
    "    run.log('train_acc5_ga', metric_logger.acc5.global_avg)\n",
    "\n",
    "def evaluate(model, criterion, data_loader, device, epoch, print_freq=100):\n",
    "    model.eval()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Test:'\n",
    "    with torch.no_grad():\n",
    "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "            # FIXME need to take into account that the datasets\n",
    "            # could have been padded in distributed setup\n",
    "            batch_size = image.shape[0]\n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "            metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "            \n",
    "            # Log metrics in Azure ML\n",
    "            run.log('val_loss', loss.item())\n",
    "            run.log('val_acc1', acc1.item())\n",
    "            run.log('val_acc5', acc5.item())\n",
    "            \n",
    "            #run.log('val_loss_{0}'.format(epoch), loss.item())\n",
    "            #run.log('val_acc1_{0}'.format(epoch), acc1.item())\n",
    "            #run.log('val_acc5_{0}'.format(epoch), acc5.item())\n",
    "            \n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "\n",
    "    print(' * Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f}'\n",
    "          .format(top1=metric_logger.acc1, top5=metric_logger.acc5))\n",
    "    \n",
    "    # Log metrics in Azure ML\n",
    "    run.log('val_acc1_ga', metric_logger.acc1.global_avg)\n",
    "    run.log('val_acc5_ga', metric_logger.acc5.global_avg)\n",
    "    \n",
    "    return metric_logger.acc1.global_avg\n",
    "\n",
    "\n",
    "def _get_cache_path(filepath):\n",
    "    import hashlib\n",
    "    h = hashlib.sha1(filepath.encode()).hexdigest()\n",
    "    cache_path = os.path.join(\"~\", \".torch\", \"vision\", \"datasets\", \"imagefolder\", h[:10] + \".pt\")\n",
    "    cache_path = os.path.expanduser(cache_path)\n",
    "    return cache_path\n",
    "\n",
    "\n",
    "def load_data(traindir, valdir, cache_dataset, distributed, input_size):\n",
    "    # Data loading code\n",
    "    print(\"Loading data\")\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    print(\"Loading training data\")\n",
    "    st = time.time()\n",
    "    cache_path = _get_cache_path(traindir)\n",
    "    if cache_dataset and os.path.exists(cache_path):\n",
    "        # Attention, as the transforms are also cached!\n",
    "        print(\"Loading dataset_train from {}\".format(cache_path))\n",
    "        dataset, _ = torch.load(cache_path)\n",
    "    else:\n",
    "        dataset = torchvision.datasets.ImageFolder(\n",
    "            traindir,\n",
    "            transforms.Compose([\n",
    "                transforms.RandomResizedCrop(input_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]))\n",
    "        if cache_dataset:\n",
    "            print(\"Saving dataset_train to {}\".format(cache_path))\n",
    "            utils.mkdir(os.path.dirname(cache_path))\n",
    "            utils.save_on_master((dataset, traindir), cache_path)\n",
    "    print(\"Took\", time.time() - st)\n",
    "\n",
    "    print(\"Loading validation data\")\n",
    "    cache_path = _get_cache_path(valdir)\n",
    "    if cache_dataset and os.path.exists(cache_path):\n",
    "        # Attention, as the transforms are also cached!\n",
    "        print(\"Loading dataset_test from {}\".format(cache_path))\n",
    "        dataset_test, _ = torch.load(cache_path)\n",
    "    else:\n",
    "        dataset_test = torchvision.datasets.ImageFolder(\n",
    "            valdir,\n",
    "            transforms.Compose([\n",
    "                transforms.Resize(input_size + 32),\n",
    "                transforms.CenterCrop(input_size),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]))\n",
    "        if cache_dataset:\n",
    "            print(\"Saving dataset_test to {}\".format(cache_path))\n",
    "            utils.mkdir(os.path.dirname(cache_path))\n",
    "            utils.save_on_master((dataset_test, valdir), cache_path)\n",
    "\n",
    "    print(\"Creating data loaders\")\n",
    "    if distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "        test_sampler = torch.utils.data.distributed.DistributedSampler(dataset_test)\n",
    "    else:\n",
    "        train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "        test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "    return dataset, dataset_test, train_sampler, test_sampler\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    if args.apex:\n",
    "        if sys.version_info < (3, 0):\n",
    "            raise RuntimeError(\"Apex currently only supports Python 3. Aborting.\")\n",
    "        if amp is None:\n",
    "            raise RuntimeError(\"Failed to import apex. Please install apex from https://www.github.com/nvidia/apex \"\n",
    "                               \"to enable mixed-precision training.\")\n",
    "\n",
    "    if args.output_dir:\n",
    "        utils.mkdir(args.output_dir)\n",
    "\n",
    "    utils.init_distributed_mode(args)\n",
    "    print(args)\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    train_dir = os.path.join(args.data_path, 'train')\n",
    "    val_dir = os.path.join(args.data_path, 'val')\n",
    "    \n",
    "    # Creating model\n",
    "    print('Creating model')\n",
    "    num_classes = len(train_dir)\n",
    "    model, input_size, params_to_update = utils.initialize_model(num_classes, args)\n",
    "    model.to(device)\n",
    "    if args.distributed and args.sync_bn:\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    \n",
    "    # Loading data\n",
    "    print('Loading data')\n",
    "    dataset, dataset_test, train_sampler, test_sampler = load_data(train_dir, val_dir, args.cache_dataset,\n",
    "                                                                   args.distributed, input_size)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=args.batch_size,\n",
    "        sampler=train_sampler, num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=args.batch_size,\n",
    "        sampler=test_sampler, num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(\n",
    "        params_to_update, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "\n",
    "    if args.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.apex_opt_level)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_step_size, gamma=args.lr_gamma)\n",
    "\n",
    "    model_without_ddp = model\n",
    "    if args.distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model) #, device_ids=[args.gpu])\n",
    "        model_without_ddp = model.module\n",
    "\n",
    "    if args.resume:\n",
    "        checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "        model_without_ddp.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "        args.start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "    if args.test_only:\n",
    "        print('Testing only')\n",
    "        evaluate(model, criterion, data_loader_test, device=device, epoch=0)\n",
    "    else:\n",
    "        print('Start training')\n",
    "        start_time = time.time()\n",
    "        for epoch in range(args.start_epoch, args.epochs):\n",
    "            if args.distributed:\n",
    "                train_sampler.set_epoch(epoch)\n",
    "            run.log('lr', optimizer.param_groups[0]['lr']) # Log metrics in Azure ML\n",
    "            train_one_epoch(model, criterion, optimizer, data_loader, device, epoch, args.print_freq, args.apex)\n",
    "            lr_scheduler.step()\n",
    "            evaluate(model, criterion, data_loader_test, device, epoch)\n",
    "            if args.output_dir:\n",
    "                checkpoint = {\n",
    "                    'model': model_without_ddp.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'args': args}\n",
    "                utils.save_on_master(\n",
    "                    checkpoint,\n",
    "                    os.path.join(args.output_dir, 'model_{}.pth'.format(epoch)))\n",
    "                utils.save_on_master(\n",
    "                    checkpoint,\n",
    "                    os.path.join(args.output_dir, 'checkpoint.pth'))\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print('Training time {}'.format(total_time_str))\n",
    "    \n",
    "    # Save model as pt and ONNX\n",
    "    dummy_input = torch.randn(args.batch_size, 3, input_size, input_size, requires_grad=True, device=device)\n",
    "    if isinstance(model, torch.nn.DataParallel) or isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "        model = model.module\n",
    "    torch.save(model, os.path.join(args.output_dir, 'model.pt'))\n",
    "    torch.onnx.export(model,\n",
    "                      dummy_input,\n",
    "                      os.path.join(args.output_dir, 'model.onnx'),\n",
    "                      export_params=True,\n",
    "                      opset_version=10,\n",
    "                      do_constant_folding=True,\n",
    "                      verbose=True,\n",
    "                      input_names = ['input'],\n",
    "                      output_names = ['output'],\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "    onnx_model = onnx.load(os.path.join(args.output_dir, 'model.onnx'))\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "\n",
    "def parse_args():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Classification Training')\n",
    "    \n",
    "    # Training parameters\n",
    "    parser.add_argument('--data-path', dest='data_path', default='/tmp/dataset/', help='dataset')\n",
    "    parser.add_argument('--dataset-name', dest='dataset_name', default=None, help='dataset name')\n",
    "    parser.add_argument('--model', default='resnet18', help='model')\n",
    "    parser.add_argument('--device', default='cuda', help='device')\n",
    "    parser.add_argument('-b', '--batch-size', default=32, type=int)\n",
    "    parser.add_argument('--epochs', default=90, type=int, metavar='N', help='number of total epochs to run')\n",
    "    parser.add_argument('-j', '--workers', default=16, type=int, metavar='N', help='number of data loading workers (default: 16)')\n",
    "    parser.add_argument('--lr', default=0.1, type=float, help='initial learning rate')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)',\n",
    "                        dest='weight_decay')\n",
    "    parser.add_argument('--lr-step-size', default=30, type=int, help='decrease lr every step-size epochs')\n",
    "    parser.add_argument('--lr-gamma', default=0.1, type=float, help='decrease lr by a factor of lr-gamma')\n",
    "    parser.add_argument('--print-freq', default=10, type=int, help='print frequency')\n",
    "    parser.add_argument('--output-dir', default='outputs', help='path where to save')\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--cache-dataset', dest='cache_dataset',\n",
    "                        help='Cache the datasets for quicker initialization. It also serializes the transforms',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--sync-bn', dest='sync_bn', help='Use sync batch norm', action='store_true')\n",
    "    parser.add_argument('--test-only', dest='test_only', help='Only test the model', action='store_true')\n",
    "    parser.add_argument('--pretrained', dest='pretrained', help='Use pre-trained models from the modelzoo', action='store_true')\n",
    "    parser.add_argument('--finetuning', dest='finetuning', help='Only finetune last layer', action='store_true')\n",
    "    \n",
    "    # Mixed precision training parameters\n",
    "    parser.add_argument('--apex', action='store_true', help='Use apex for mixed precision training')\n",
    "    parser.add_argument('--apex-opt-level', default='O1', type=str,\n",
    "                        help='For apex mixed precision training'\n",
    "                             'O0 for FP32 training, O1 for mixed precision training.'\n",
    "                             'For further detail, see https://github.com/NVIDIA/apex/tree/master/examples/imagenet')\n",
    "    \n",
    "    # Distributed training parameters\n",
    "    parser.add_argument('--world-size', dest='world_size', default=1, type=int, help='number of distributed processes')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "    parser.add_argument('--dist-url', type=str, help='url used to set up distributed training')\n",
    "    parser.add_argument('--rank', default=-1, type=int, help='rank of the worker')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Load data path from run\n",
    "    try:\n",
    "        args.data_path = run.input_datasets[args.dataset_name]\n",
    "    except:\n",
    "        print('Could not find registered dataset. Loading default data path.')\n",
    "    return args\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An *Experiment* is a logical container in an Azure ML Workspace that represents a collection of trials (individual model runs). It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Fill in the missing values below to create a new experiment in your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name='ch3-pytorch_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An estimator object is used to submit the run. Azure Machine Learning has pre-configured estimators for common machine learning frameworks, as well as generic Estimator. Create a generic estimator for by specifying\n",
    "\n",
    "- The name of the estimator object, est\n",
    "- The directory that contains your scripts. All the files in this directory are uploaded into the cluster nodes for execution.\n",
    "- The training script name, train_titanic.py\n",
    "- The input Dataset for training\n",
    "- The compute target. In this case you will use the AmlCompute you created\n",
    "- The environment definition for the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Complete the estimator creation below.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.estimator.estimator?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch, Nccl\n",
    "\n",
    "script_params = {\n",
    "    '--dataset-name': 'hymenoptera_data',\n",
    "    '--dist-backend': 'nccl',\n",
    "    '--dist-url': '$AZ_BATCHAI_PYTORCH_INIT_METHOD',\n",
    "    '--rank': '$AZ_BATCHAI_TASK_INDEX',\n",
    "    '--world-size': 2,\n",
    "    '--epochs': 4,\n",
    "    '--pretrained': None,\n",
    "    '--finetuning': None\n",
    "}\n",
    "\n",
    "est = PyTorch(source_directory=TRAIN_FOLDER_NAME,\n",
    "              entry_script=TRAIN_FILE_NAME,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              node_count=2,\n",
    "              inputs=[file_dataset.as_named_input('hymenoptera_data').as_mount('tmp/dataset_new')],\n",
    "              distributed_training=Nccl(),\n",
    "              use_gpu=True,\n",
    "              framework_version='1.3',\n",
    "              pip_packages=['azureml-dataprep[pandas,fuse]', 'onnx', 'Pillow==6.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Alternative\n",
    "from azureml.train.dnn import PyTorch, Gloo\n",
    "\n",
    "script_params = {\n",
    "    '--dataset-name': 'hymenoptera_data'\n",
    "    '--dist-backend' : 'gloo',\n",
    "    '--dist-url': '$AZ_BATCHAI_PYTORCH_INIT_METHOD',\n",
    "    '--rank': '$AZ_BATCHAI_TASK_INDEX',\n",
    "    '--world-size': 1,\n",
    "    '--epochs': 1\n",
    "}\n",
    "\n",
    "est = PyTorch(source_directory=TRAIN_FOLDER_NAME,\n",
    "              entry_script=TRAIN_FILE_NAME,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              node_count=1,\n",
    "              inputs=[file_dataset.as_named_input('hymenoptera_data').as_mount('tmp/dataset')],\n",
    "              distributed_training=Gloo(),\n",
    "              use_gpu=True,\n",
    "              framework_version='1.3',\n",
    "              pip_packages=['azureml-dataprep[pandas,fuse]', 'onnx', 'Pillow==6.1'])\n",
    "              \n",
    "# not distributed\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--dataset-name': 'hymenoptera_data',\n",
    "    '--dist-backend': 'nccl',\n",
    "    '--dist-url': '$AZ_BATCHAI_PYTORCH_INIT_METHOD',\n",
    "    '--rank': '$AZ_BATCHAI_TASK_INDEX',\n",
    "    '--world-size': 1,\n",
    "    '--epochs': 1,\n",
    "    '--pretrained': None,\n",
    "    '--finetuning': None\n",
    "}\n",
    "\n",
    "est = PyTorch(source_directory=TRAIN_FOLDER_NAME,\n",
    "              entry_script=TRAIN_FILE_NAME,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              node_count=1,\n",
    "              inputs=[file_dataset.as_named_input('hymenoptera_data').as_mount('tmp/dataset')],\n",
    "              use_gpu=True,\n",
    "              framework_version='1.3',\n",
    "              pip_packages=['azureml-dataprep[pandas,fuse]', 'onnx', 'Pillow==6.1'])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Submit the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the estimator to the Azure ML experiment to kick off the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Submit the experiment as a new run.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment%28class%29?view=azure-ml-py#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run = exp.submit(est)\n",
    "run.wait_for_completion(show_output=True, wait_post_processing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a model trained on a remote cluster. Retrieve all the metrics logged during the run, including the accuracy of the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Retrieve the metrics of the run.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run%28class%29?view=azure-ml-py#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register model from run\n",
    "from azureml.core import Model\n",
    "\n",
    "model = run.register_model(model_name='ch3-pytorch-model',\n",
    "                           model_path='outputs/model.onnx',\n",
    "                           model_framework=Model.Framework.ONNX,\n",
    "                           model_framework_version='1.3',\n",
    "                           datasets=[('Training dataset', file_dataset)],\n",
    "                           description='PyTorch hymenoptera classification.',\n",
    "                           tags={'area': 'hymenoptera_data', 'type': 'pytorch'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
