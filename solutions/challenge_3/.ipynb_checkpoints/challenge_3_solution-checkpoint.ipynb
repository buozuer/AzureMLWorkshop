{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Basics of Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of this challenge you will get familar with the basic concepts of [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/). Relevant links will provided in the Notebook and help you to solve the tasks.\n",
    "\n",
    "Generally a very good source of information is the [Python SDK reference](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py) for Azure Machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Azure ML Python Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception RunType azureml.scriptrun already has a factory, can't add another.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.83\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Authentication and initializing Azure Machine Learning Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step you have to authenticate against the Azure [Machine Learning Workspace](https://ml.azure.com/). This can be achieved in different ways:\n",
    "\n",
    "1. **Interactive Login Authentication:** The interactive authentication is suitable for local experimentation on your own computer.\n",
    "2. **Azure CLI Authentication:** Azure CLI authentication is suitable if you are already using Azure CLI for managing Azure resources, and want to sign in only once.\n",
    "3. **Managed Service Identity (MSI) Authentication:** The MSI authentication is suitable for automated workflows, for example as part of Azure Devops build.\n",
    "4. **Service Principal Authentication:** The Service Principal authentication is suitable for automated workflows, for example as part of Azure Devops build.\n",
    "\n",
    "For now, we will use the interactive authentication, which is the default mode when using Azure ML SDK. When you connect to your workspace using `Workspace.from_config`, you will get an interactive login dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the user you're authenticated as must have access to the subscription and resource group. If you receive an error\n",
    "```\n",
    "AuthenticationException: You don't have access to xxxxxx-xxxx-xxx-xxx-xxxxxxxxxx subscription. All the subscriptions that you have access to = ...\n",
    "```\n",
    "check that the you used correct login and entered the correct subscription ID.\n",
    "\n",
    "Alternatively, you can also specify the details of your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Alternative login method\\n\\nfrom azureml.core.authentication import InteractiveLoginAuthentication\\n\\ninteractive_auth = InteractiveLoginAuthentication()\\n\\nws = Workspace(subscription_id='<your-subscription-id>',\\n               resource_group='<your-resource-group-name>',\\n               workspace_name='<your-workspace-name>',\\n               auth=interactive_auth)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Alternative login method\n",
    "\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "\n",
    "ws = Workspace(subscription_id='<your-subscription-id>',\n",
    "               resource_group='<your-resource-group-name>',\n",
    "               workspace_name='<your-workspace-name>',\n",
    "               auth=interactive_auth)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we logged in, we can print the Worspace details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Print the workspace details below. See here for the workspace object reference: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: myworkspace\n",
      "Azure region: westeurope\n",
      "Subscription id: 558bd446-4212-46a2-908c-9ab0a628705e\n",
      "Resource group: azure-ml-service-rg\n"
     ]
    }
   ],
   "source": [
    "print(\"Workspace name: \" + ws.name, \n",
    "      \"Azure region: \" + ws.location, \n",
    "      \"Subscription id: \" + ws.subscription_id, \n",
    "      \"Resource group: \" + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and register datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To register an Azure blob container as a datastore, use [register_azure_blob-container()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.datastore(class)?view=azure-ml-py#register-azure-blob-container-workspace--datastore-name--container-name--account-name--sas-token-none--account-key-none--protocol-none--endpoint-none--overwrite-false--create-if-not-exists-false--skip-validation-false--blob-cache-timeout-none--grant-workspace-access-false--subscription-id-none--resource-group-none-).\n",
    "\n",
    "The following code creates and registers the `blob_datastore_name` datastore to the `ws` workspace. This datastore accesses the `my-container-name` blob container on the `my-account-name` storage account, by using the provided account key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_datastore_name='<my-name-in-ws>' # Name of the datastore to workspace\n",
    "container_name = '<my-container-name>' # Name of Azure blob container\n",
    "account_name = '<my-account-name>' # Storage account name\n",
    "account_key = '<my-account-key>' # Storage account key\n",
    "\n",
    "blob_datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                         datastore_name=blob_datastore_name, \n",
    "                                                         container_name=container_name, \n",
    "                                                         account_name=account_name,\n",
    "                                                         account_key=account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload and register data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every workspace comes with a default [datastore](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data) (and you can register more) which is backed by the Azure blob storage account associated with the workspace. We can use it to transfer data from local to the cloud, and create Dataset from it. We will now upload the Iris data to the default datastore (blob) within your workspace.\n",
    "\n",
    "By creating a dataset, you create a reference to the data source location. If you applied any subsetting transformations to the dataset, they will be stored in the dataset as well. The data remains in its existing location, so no extra storage cost is incurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspacefilestore AzureFile\n",
      "workspaceblobstore AzureBlob\n",
      "myworkspstoragebqrsddbr__azureml_blobstore_8772624c_5964_4ac6_b73d_42b03c4e019e AzureBlob\n",
      "azureml_globaldatasets AzureBlob\n",
      "smtprodweu1globaluploadedresources AzureBlob\n"
     ]
    }
   ],
   "source": [
    "# List all datastores registered in the current workspace\n",
    "datastores = ws.datastores\n",
    "for name, datastore in datastores.items():\n",
    "    print(name, datastore.datastore_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this challenge we will use the [default datastore](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-access-data#get-datastores-from-your-workspace) that comes with the Azure Machine Learning Workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Retrieve the default datastore for this workspace.\n",
    "\n",
    "Hint: Same link as in the previous hint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore\n",
      "AzureBlob\n",
      "myworkspstoragebqrsddbr\n",
      "azureml-blobstore-8772624c-5964-4ac6-b73d-42b03c4e019e\n"
     ]
    }
   ],
   "source": [
    "# get the default datastore\n",
    "datastore = ws.get_default_datastore()\n",
    "print(datastore.name, datastore.datastore_type, datastore.account_name, datastore.container_name, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Upload the file `./train-dataset/iris.csv` to the target path `train-dataset/tabular/` on the default datastore.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.azure_storage_datastore.azureblobdatastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 397 files\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\1743840368_b5ccda82b7.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\1804095607_0341701e1c.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\1808777855_2a895621d7.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\1917341202_d00a7f9af5.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\1924473702_daa9aacdbe.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2019439677_2db655d361.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2039585088_c6f47c592e.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2104709400_8831b4fc6f.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2127908701_d49dc83c97.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2191997003_379df31291.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2211974567_ee4606b493.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2219621907_47bc7cc6b0.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2238242353_52c82441df.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2255445811_dabcdf7258.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2265824718_2c96f485da.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2265825502_fff99cfd2d.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2278278459_6b99605e50.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2288450226_a6e96e8fdf.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2288481644_83ff7e4572.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\2292213964_ca51ce4bef.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\Ant-1818.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\Ant_1.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\F.pergan.28(f).jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\Hormiga.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\MehdiabadiAnt2_600.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\Nepenthes_rafflesiana_ant.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\ant photos.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\ants-devouring-remains-of-large-dead-insect-on-red-tile-in-Stellenbosch-South-Africa-closeup-1-DHD.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\army-ants-red-picture.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\desert_ant.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\formica.jpeg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\1693954099_46d4c20605.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\1808777855_2a895621d7.jpg, 1 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\VietnameseAntMimicSpider.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\VietnameseAntMimicSpider.jpg, 2 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\hormiga_co_por.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\hormiga_co_por.jpg, 3 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\kurokusa.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\kurokusa.jpg, 4 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\swiss-army-ant.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\ant photos.jpg, 5 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\termite-vs-ant.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2127908701_d49dc83c97.jpg, 6 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\ants\\trap-jaw-ant-insect-bg.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2104709400_8831b4fc6f.jpg, 7 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\10870992_eebeeb3a12.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2265825502_fff99cfd2d.jpg, 8 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\129236073_0985e91c7d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2255445811_dabcdf7258.jpg, 9 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\132511197_0b86ad0fff.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\1804095607_0341701e1c.jpg, 10 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\1693954099_46d4c20605.jpg, 11 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\132826773_dbbcb117b9.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\144098310_a4176fd54d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\Ant_1.jpg, 12 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\149973093_da3c446268.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\army-ants-red-picture.jpg, 13 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\150013791_969d9a968b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\formica.jpeg, 14 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\151594775_ee7dc17b60.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\trap-jaw-ant-insect-bg.jpg, 15 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\151603988_2c6f7d14c7.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\Ant-1818.jpg, 16 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\152789693_220b003452.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\termite-vs-ant.jpg, 17 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\154600396_53e1252e52.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\132826773_dbbcb117b9.jpg, 18 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\16838648_415acd9e3f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\swiss-army-ant.jpg, 19 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\17209602_fe5a5a746f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\F.pergan.28(f).jpg, 20 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\174142798_e5ad6d76e0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2238242353_52c82441df.jpg, 21 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\177677657_a38c97e572.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2292213964_ca51ce4bef.jpg, 22 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\181171681_c5a1a82ded.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\MehdiabadiAnt2_600.jpg, 23 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\187130242_4593a4c610.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\181171681_c5a1a82ded.jpg, 24 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\196430254_46bd129ae7.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\17209602_fe5a5a746f.jpg, 25 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\196658222_3fffd79c67.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\174142798_e5ad6d76e0.jpg, 26 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\198508668_97d818b6c4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\1743840368_b5ccda82b7.jpg, 27 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\203868383_0fcbb48278.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\129236073_0985e91c7d.jpg, 28 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\205835650_e6f2614bee.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2219621907_47bc7cc6b0.jpg, 29 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\208702903_42fb4d9748.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\1924473702_daa9aacdbe.jpg, 30 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\21399619_3e61e5bb6f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\1917341202_d00a7f9af5.jpg, 31 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\26589803_5ba7000313.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\152789693_220b003452.jpg, 32 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\29494643_e3410f0d37.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2019439677_2db655d361.jpg, 33 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\desert_ant.jpg, 34 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\36900412_92b81831ad.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\39672681_1302d204d1.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\10870992_eebeeb3a12.jpg, 35 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\39747887_42df2855ee.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2288481644_83ff7e4572.jpg, 36 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\44105569_16720a960c.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\26589803_5ba7000313.jpg, 37 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\177677657_a38c97e572.jpg, 38 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\54736755_c057723f64.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\57459255_752774f1b2.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\151603988_2c6f7d14c7.jpg, 39 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\59798110_2b6a3c8031.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\Hormiga.jpg, 40 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\65038344_52a45d090d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\21399619_3e61e5bb6f.jpg, 41 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\6a00d8341c630a53ef00e553d0beb18834-800wi.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\154600396_53e1252e52.jpg, 42 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\196430254_46bd129ae7.jpg, 43 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\72100438_73de9f17af.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\85112639_6e860b0469.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\150013791_969d9a968b.jpg, 44 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\90179376_abc234e5f4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2191997003_379df31291.jpg, 45 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\92663402_37f379e57a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\36900412_92b81831ad.jpg, 46 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\95238259_98470c5b10.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2278278459_6b99605e50.jpg, 47 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\test\\bees\\98391118_bdb1e80cce.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\39672681_1302d204d1.jpg, 48 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1030023514_aad5c608f9.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2039585088_c6f47c592e.jpg, 49 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1053149811_f62a3410d3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\39747887_42df2855ee.jpg, 50 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1073564163_225a64f170.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\ants-devouring-remains-of-large-dead-insect-on-red-tile-in-Stellenbosch-South-Africa-closeup-1-DHD.jpg, 51 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1095476100_3906d8afde.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\203868383_0fcbb48278.jpg, 52 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1099452230_d1949d3250.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\90179376_abc234e5f4.jpg, 53 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1119630822_cd325ea21a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2211974567_ee4606b493.jpg, 54 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1124525276_816a07c17f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\44105569_16720a960c.jpg, 55 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\187130242_4593a4c610.jpg, 56 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1225872729_6f0856588f.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1247887232_edcb61246c.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1053149811_f62a3410d3.jpg, 57 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1262751255_c56c042b7b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\65038344_52a45d090d.jpg, 58 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1262877379_64fcada201.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\95238259_98470c5b10.jpg, 59 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1269756697_0bce92cdab.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\72100438_73de9f17af.jpg, 60 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1286984635_5119e80de1.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\16838648_415acd9e3f.jpg, 61 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1337725712_2eb53cd742.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\208702903_42fb4d9748.jpg, 62 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1358854066_5ad8015f7f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2288450226_a6e96e8fdf.jpg, 63 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1360291657_dc248c5eea.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1030023514_aad5c608f9.jpg, 64 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1368913450_e146e2fb6d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1095476100_3906d8afde.jpg, 65 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1440002809_b268d9a66a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1247887232_edcb61246c.jpg, 66 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1473187633_63ccaacea6.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1269756697_0bce92cdab.jpg, 67 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1489674356_09d48dde0a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\54736755_c057723f64.jpg, 68 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\150801003_3390b73135.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1262751255_c56c042b7b.jpg, 69 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\150801171_cd86f17ed8.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\57459255_752774f1b2.jpg, 70 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\152286280_411648ec27.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1262877379_64fcada201.jpg, 71 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\153320619_2aeb5fa0ee.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\196658222_3fffd79c67.jpg, 72 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\153783656_85f9c3ac70.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\132511197_0b86ad0fff.jpg, 73 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\154124431_65460430f2.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1286984635_5119e80de1.jpg, 74 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\157401988_d0564a9d02.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1225872729_6f0856588f.jpg, 75 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\159515240_d5981e20d1.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1368913450_e146e2fb6d.jpg, 76 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\161076144_124db762d6.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1124525276_816a07c17f.jpg, 77 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\161292361_c16e0bf57a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\85112639_6e860b0469.jpg, 78 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\162603798_40b51f1654.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1119630822_cd325ea21a.jpg, 79 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\1660097129_384bf54490.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1099452230_d1949d3250.jpg, 80 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\167890289_dd5ba923f3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\152286280_411648ec27.jpg, 81 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\198508668_97d818b6c4.jpg, 82 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\170652283_ecdaff5d1a.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\172772109_d0a8e15fb0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\205835650_e6f2614bee.jpg, 83 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\175998972.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1489674356_09d48dde0a.jpg, 84 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\178538489_bec7649292.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1473187633_63ccaacea6.jpg, 85 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\181942028_961261ef48.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\150801171_cd86f17ed8.jpg, 86 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\183260961_64ab754c97.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1337725712_2eb53cd742.jpg, 87 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\188552436_605cc9b36b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\154124431_65460430f2.jpg, 88 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\196057951_63bf063b92.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\153783656_85f9c3ac70.jpg, 89 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\196757565_326437f5fe.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\157401988_d0564a9d02.jpg, 90 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\201558278_fe4caecc76.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\159515240_d5981e20d1.jpg, 91 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\201790779_527f4c0168.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1073564163_225a64f170.jpg, 92 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\205398178_c395c5e460.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\150801003_3390b73135.jpg, 93 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\207947948_3ab29d7207.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\161292361_c16e0bf57a.jpg, 94 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\208072188_f293096296.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\183260961_64ab754c97.jpg, 95 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\209615353_eeb38ba204.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\170652283_ecdaff5d1a.jpg, 96 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\175998972.jpg, 97 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\212100470_b485e7b7b9.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\224655713_3956f7d39a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\29494643_e3410f0d37.jpg, 98 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\226951206_d6bf946504.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1358854066_5ad8015f7f.jpg, 99 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\239161491_86ac23b0a3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1360291657_dc248c5eea.jpg, 100 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\245647475_9523dfd13e.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\172772109_d0a8e15fb0.jpg, 101 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\255434217_1b2b3fe0a4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\205398178_c395c5e460.jpg, 102 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\258217966_d9d90d18d3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\178538489_bec7649292.jpg, 103 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\263615709_cfb28f6b8e.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\98391118_bdb1e80cce.jpg, 104 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\275429470_b2d7d9290b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\196057951_63bf063b92.jpg, 105 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\308196310_1db5ffa01b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1660097129_384bf54490.jpg, 106 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\318052216_84dff3f98a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\153320619_2aeb5fa0ee.jpg, 107 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\319494379_648fb5a1c6.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\201558278_fe4caecc76.jpg, 108 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\334167043_cbd1adaeb9.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\167890289_dd5ba923f3.jpg, 109 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\339670531_94b75ae47a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\6a00d8341c630a53ef00e553d0beb18834-800wi.jpg, 110 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\342438950_a3da61deab.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\188552436_605cc9b36b.jpg, 111 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\374435068_7eee412ec4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\208072188_f293096296.jpg, 112 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\382971067_0bfd33afe0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\275429470_b2d7d9290b.jpg, 113 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\384191229_5779cf591b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\209615353_eeb38ba204.jpg, 114 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\386190770_672743c9a7.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\181942028_961261ef48.jpg, 115 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\59798110_2b6a3c8031.jpg, 116 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\392382602_1b7bed32fa.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\403746349_71384f5b58.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\207947948_3ab29d7207.jpg, 117 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\408393566_b5b694119b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\201790779_527f4c0168.jpg, 118 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\412436937_4c2378efc2.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\403746349_71384f5b58.jpg, 119 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\424119020_6d57481dab.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\1440002809_b268d9a66a.jpg, 120 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\424873399_47658a91fb.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\308196310_1db5ffa01b.jpg, 121 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\436944325_d4925a38c7.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\382971067_0bfd33afe0.jpg, 122 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\445356866_6cb3289067.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\255434217_1b2b3fe0a4.jpg, 123 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\450057712_771b3bfc91.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\212100470_b485e7b7b9.jpg, 124 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\459442412_412fecf3fe.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\196757565_326437f5fe.jpg, 125 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\459694881_ac657d3187.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\224655713_3956f7d39a.jpg, 126 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\460372577_f2f6a8c9fc.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\374435068_7eee412ec4.jpg, 127 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\460874319_0a45ab4d05.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\384191229_5779cf591b.jpg, 128 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\466430434_4000737de9.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\339670531_94b75ae47a.jpg, 129 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\470127037_513711fd21.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\342438950_a3da61deab.jpg, 130 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\470127071_8b8ee2bd74.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\408393566_b5b694119b.jpg, 131 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\474806473_ca6caab245.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\424119020_6d57481dab.jpg, 132 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\475961153_b8c13fd405.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\161076144_124db762d6.jpg, 133 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\477437164_bc3e6e594a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\436944325_d4925a38c7.jpg, 134 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\484293231_e53cfc0c89.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\318052216_84dff3f98a.jpg, 135 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\488272201_c5aa281348.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\392382602_1b7bed32fa.jpg, 136 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\502717153_3e4865621a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\226951206_d6bf946504.jpg, 137 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\506249802_207cd979b4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\162603798_40b51f1654.jpg, 138 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\506249836_717b73f540.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\459694881_ac657d3187.jpg, 139 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\512164029_c0a66b8498.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\460372577_f2f6a8c9fc.jpg, 140 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\512863248_43c8ce579b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\239161491_86ac23b0a3.jpg, 141 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\518746016_bcc28f8b5b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\424873399_47658a91fb.jpg, 142 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\518773929_734dbc5ff4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\475961153_b8c13fd405.jpg, 143 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\522163566_fec115ca66.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\319494379_648fb5a1c6.jpg, 144 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\522415432_2218f34bf8.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\470127071_8b8ee2bd74.jpg, 145 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\531979952_bde12b3bc0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\460874319_0a45ab4d05.jpg, 146 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\533848102_70a85ad6dd.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\258217966_d9d90d18d3.jpg, 147 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\535522953_308353a07c.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\459442412_412fecf3fe.jpg, 148 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\540543309_ddbb193ee5.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\445356866_6cb3289067.jpg, 149 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\540889389_48bb588b21.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\412436937_4c2378efc2.jpg, 150 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\541630764_dbd285d63c.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\92663402_37f379e57a.jpg, 151 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\543417860_b14237f569.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\474806473_ca6caab245.jpg, 152 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\560966032_988f4d7bc4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\484293231_e53cfc0c89.jpg, 153 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\562589509_7e55469b97.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\522163566_fec115ca66.jpg, 154 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\573151833_ebbc274b77.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\245647475_9523dfd13e.jpg, 155 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\649026570_e58656104b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\149973093_da3c446268.jpg, 156 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\649407494_9b6bc4949f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\518773929_734dbc5ff4.jpg, 157 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\662541407_ff8db781e7.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\477437164_bc3e6e594a.jpg, 158 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\684133190_35b62c0c1d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\512164029_c0a66b8498.jpg, 159 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\707895295_009cf23188.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\522415432_2218f34bf8.jpg, 160 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\751649788_78dd7d16ce.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\531979952_bde12b3bc0.jpg, 161 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\768870506_8f115d3d37.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\450057712_771b3bfc91.jpg, 162 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\795000156_a9900a4a71.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\512863248_43c8ce579b.jpg, 163 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\822537660_caf4ba5514.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\466430434_4000737de9.jpg, 164 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\841049277_b28e58ad05.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\502717153_3e4865621a.jpg, 165 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\854534770_31f6156383.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\540889389_48bb588b21.jpg, 166 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\886401651_f878e888cd.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\560966032_988f4d7bc4.jpg, 167 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\892108839_f1aad4ca46.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\573151833_ebbc274b77.jpg, 168 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\892676922_4ab37dce07.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\518746016_bcc28f8b5b.jpg, 169 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\938946700_ca1c669085.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\334167043_cbd1adaeb9.jpg, 170 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\957233405_25c1d1187b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\543417860_b14237f569.jpg, 171 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\ants\\998118368_6ac1d91f81.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\707895295_009cf23188.jpg, 172 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1032546534_06907fe3b3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\768870506_8f115d3d37.jpg, 173 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1092977343_cb42b38d62.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\540543309_ddbb193ee5.jpg, 174 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1093831624_fb5fbe2308.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\562589509_7e55469b97.jpg, 175 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1097045929_1753d1c765.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\535522953_308353a07c.jpg, 176 files out of an estimated total of 397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1181173278_23c36fac71.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\506249836_717b73f540.jpg, 177 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1232245714_f862fbe385.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\263615709_cfb28f6b8e.jpg, 178 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1295655112_7813f37d21.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\649407494_9b6bc4949f.jpg, 179 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1297972485_33266a18d9.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\795000156_a9900a4a71.jpg, 180 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1328423762_f7a88a8451.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\684133190_35b62c0c1d.jpg, 181 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1355974687_1341c1face.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\998118368_6ac1d91f81.jpg, 182 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1486120850_490388f84b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\886401651_f878e888cd.jpg, 183 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1508176360_2972117c9d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\822537660_caf4ba5514.jpg, 184 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1519368889_4270261ee3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1093831624_fb5fbe2308.jpg, 185 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1691282715_0addfdf5e8.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1092977343_cb42b38d62.jpg, 186 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1799726602_8580867f71.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1328423762_f7a88a8451.jpg, 187 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1799729694_0c40101071.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\662541407_ff8db781e7.jpg, 188 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\1807583459_4fe92b3133.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1486120850_490388f84b.jpg, 189 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2031225713_50ed499635.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1232245714_f862fbe385.jpg, 190 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2037437624_2d7bce461f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\957233405_25c1d1187b.jpg, 191 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2053200300_8911ef438a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\854534770_31f6156383.jpg, 192 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2060668999_e11edb10d0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1097045929_1753d1c765.jpg, 193 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2086294791_6f3789d8a6.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\892108839_f1aad4ca46.jpg, 194 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2103637821_8d26ee6b90.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1691282715_0addfdf5e8.jpg, 195 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2104135106_a65eede1de.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\488272201_c5aa281348.jpg, 196 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\215512424_687e1e0821.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\938946700_ca1c669085.jpg, 197 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2173503984_9c6aaaa7e2.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\841049277_b28e58ad05.jpg, 198 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2031225713_50ed499635.jpg, 199 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\220376539_20567395d8.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2227611847_ec72d40403.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1295655112_7813f37d21.jpg, 200 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2053200300_8911ef438a.jpg, 201 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\224841383_d050f5f510.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2321139806_d73d899e66.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1799729694_0c40101071.jpg, 202 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2321144482_f3785ba7b2.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1508176360_2972117c9d.jpg, 203 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\506249802_207cd979b4.jpg, 204 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2330918208_8074770c20.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2345177635_caf07159b3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2060668999_e11edb10d0.jpg, 205 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2358061370_9daabbd9ac.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1181173278_23c36fac71.jpg, 206 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2364597044_3c3e3fc391.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\470127037_513711fd21.jpg, 207 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\238161922_55fa9a76ae.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\541630764_dbd285d63c.jpg, 208 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2384149906_2cd8b0b699.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1519368889_4270261ee3.jpg, 209 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2397446847_04ef3cd3e1.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1799726602_8580867f71.jpg, 210 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2405441001_b06c36fa72.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1032546534_06907fe3b3.jpg, 211 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2407809945_fb525ef54d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\220376539_20567395d8.jpg, 212 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1297972485_33266a18d9.jpg, 213 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2415414155_1916f03b42.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2438480600_40a1249879.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2173503984_9c6aaaa7e2.jpg, 214 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2444778727_4b781ac424.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\892676922_4ab37dce07.jpg, 215 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2445215254_51698ff797.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\533848102_70a85ad6dd.jpg, 216 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2452236943_255bfd9e58.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2086294791_6f3789d8a6.jpg, 217 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2457841282_7867f16639.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2330918208_8074770c20.jpg, 218 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2467959963_a7831e9ff0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\2265824718_2c96f485da.jpg, 219 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2470492902_3572c90f75.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2384149906_2cd8b0b699.jpg, 220 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2470492904_837e97800d.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2444778727_4b781ac424.jpg, 221 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2477324698_3d4b1b1cab.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\386190770_672743c9a7.jpg, 222 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2477349551_e75c97cf4d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2397446847_04ef3cd3e1.jpg, 223 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2478216347_535c8fe6d7.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2467959963_a7831e9ff0.jpg, 224 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2486729079_62df0920be.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2364597044_3c3e3fc391.jpg, 225 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2438480600_40a1249879.jpg, 226 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2486746709_c43cec0e42.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2452236943_255bfd9e58.jpg, 227 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2493379287_4100e1dacc.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2495722465_879acf9d85.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2407809945_fb525ef54d.jpg, 228 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2501530886_e20952b97d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2445215254_51698ff797.jpg, 229 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2506114833_90a41c5267.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2415414155_1916f03b42.jpg, 230 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2509402554_31821cb0b6.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2104135106_a65eede1de.jpg, 231 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2525379273_dcb26a516d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2405441001_b06c36fa72.jpg, 232 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2528444139_fa728b0f5b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2037437624_2d7bce461f.jpg, 233 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2538361678_9da84b77e3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\751649788_78dd7d16ce.jpg, 234 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2551813042_8a070aeb2b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2525379273_dcb26a516d.jpg, 235 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2580598377_a4caecdb54.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2457841282_7867f16639.jpg, 236 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2601176055_8464e6aa71.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\215512424_687e1e0821.jpg, 237 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2610833167_79bf0bcae5.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2486729079_62df0920be.jpg, 238 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2610838525_fe8e3cae47.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\238161922_55fa9a76ae.jpg, 239 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2617161745_fa3ebe85b4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2506114833_90a41c5267.jpg, 240 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2625499656_e3415e374d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2470492902_3572c90f75.jpg, 241 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2634617358_f32fd16bea.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2528444139_fa728b0f5b.jpg, 242 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2638074627_6b3ae746a0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2617161745_fa3ebe85b4.jpg, 243 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2645107662_b73a8595cc.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2227611847_ec72d40403.jpg, 244 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2651621464_a2fa8722eb.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2538361678_9da84b77e3.jpg, 245 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2652877533_a564830cbf.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2321139806_d73d899e66.jpg, 246 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\266644509_d30bb16a1b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2601176055_8464e6aa71.jpg, 247 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2668391343_45e272cd07.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2103637821_8d26ee6b90.jpg, 248 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2321144482_f3785ba7b2.jpg, 249 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2670536155_c170f49cd0.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2683605182_9d2a0c66cf.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2470492904_837e97800d.jpg, 250 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2685605303_9eed79d59d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2625499656_e3415e374d.jpg, 251 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2702408468_d9ed795f4f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2610833167_79bf0bcae5.jpg, 252 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2704348794_eb5d5178c2.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2358061370_9daabbd9ac.jpg, 253 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\2707440199_cd170bd512.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2509402554_31821cb0b6.jpg, 254 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\272986700_d4d4bf8c4b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2651621464_a2fa8722eb.jpg, 255 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\279113587_b4843db199.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2634617358_f32fd16bea.jpg, 256 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\290082189_f66cb80bfc.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1807583459_4fe92b3133.jpg, 257 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\296565463_d07a7bed96.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2477324698_3d4b1b1cab.jpg, 258 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\342758693_c56b89b6b6.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2645107662_b73a8595cc.jpg, 259 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\348291597_ee836fbb1a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\266644509_d30bb16a1b.jpg, 260 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\350436573_41f4ecb6c8.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\ants\\649026570_e58656104b.jpg, 261 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\353266603_d3eac7e9a0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\279113587_b4843db199.jpg, 262 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\354167719_22dca13752.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2495722465_879acf9d85.jpg, 263 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\359928878_b3b418c728.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2345177635_caf07159b3.jpg, 264 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\365759866_b15700c59b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2580598377_a4caecdb54.jpg, 265 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\372228424_16da1f8884.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2668391343_45e272cd07.jpg, 266 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\400262091_701c00031c.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2477349551_e75c97cf4d.jpg, 267 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\416144384_961c326481.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2685605303_9eed79d59d.jpg, 268 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\421515404_e87569fd8b.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\296565463_d07a7bed96.jpg, 269 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\444532809_9e931e2279.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2707440199_cd170bd512.jpg, 270 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\446296270_d9e8b93ecf.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2652877533_a564830cbf.jpg, 271 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\452462677_7be43af8ff.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\1355974687_1341c1face.jpg, 272 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\452462695_40a4e5b559.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2478216347_535c8fe6d7.jpg, 273 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\456097971_860949c4fc.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2702408468_d9ed795f4f.jpg, 274 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\457457145_5f86eb7e9c.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\400262091_701c00031c.jpg, 275 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\464594019_1b24a28bb1.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\342758693_c56b89b6b6.jpg, 276 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\465133211_80e0c27f60.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\353266603_d3eac7e9a0.jpg, 277 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\469333327_358ba8fe8a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2683605182_9d2a0c66cf.jpg, 278 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\472288710_2abee16fa0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2493379287_4100e1dacc.jpg, 279 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\473618094_8ffdcab215.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2704348794_eb5d5178c2.jpg, 280 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\476347960_52edd72b06.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\272986700_d4d4bf8c4b.jpg, 281 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\478701318_bbd5e557b8.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\350436573_41f4ecb6c8.jpg, 282 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\485743562_d8cc6b8f73.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2638074627_6b3ae746a0.jpg, 283 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\507288830_f46e8d4cb2.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\416144384_961c326481.jpg, 284 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\446296270_d9e8b93ecf.jpg, 285 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\509247772_2db2d01374.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\513545352_fd3e7c7c5d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2610838525_fe8e3cae47.jpg, 286 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\522104315_5d3cb2758e.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\365759866_b15700c59b.jpg, 287 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\537309131_532bfa59ea.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\464594019_1b24a28bb1.jpg, 288 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\540976476_844950623f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\290082189_f66cb80bfc.jpg, 289 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\576452297_897023f002.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\444532809_9e931e2279.jpg, 290 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\586041248_3032e277a9.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\465133211_80e0c27f60.jpg, 291 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\586474709_ae436da045.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2501530886_e20952b97d.jpg, 292 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\590318879_68cf112861.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\456097971_860949c4fc.jpg, 293 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\603709866_a97c7cfc72.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\576452297_897023f002.jpg, 294 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\603711658_4c8cd2201e.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\472288710_2abee16fa0.jpg, 295 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\759745145_e8bc776ec8.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\507288830_f46e8d4cb2.jpg, 296 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\760526046_547e8b381f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\485743562_d8cc6b8f73.jpg, 297 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\476347960_52edd72b06.jpg, 298 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\760568592_45a52c847f.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\774440991_63a4aa0cbe.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\354167719_22dca13752.jpg, 299 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\873076652_eb098dab2d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\469333327_358ba8fe8a.jpg, 300 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\936182217_c4caa5222d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\457457145_5f86eb7e9c.jpg, 301 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\train\\bees\\969455125_58c797ef17.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\586041248_3032e277a9.jpg, 302 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\0013035.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\452462695_40a4e5b559.jpg, 303 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\10308379_1b6c72e180.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\224841383_d050f5f510.jpg, 304 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\11381045_b352a47d8c.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2670536155_c170f49cd0.jpg, 305 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\116570827_e9c126745d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\759745145_e8bc776ec8.jpg, 306 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\119785936_dd428e40c3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\151594775_ee7dc17b60.jpg, 307 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\132478121_2a430adea2.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2486746709_c43cec0e42.jpg, 308 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\147542264_79506478c2.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\513545352_fd3e7c7c5d.jpg, 309 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\148715752_302c84f5a4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\372228424_16da1f8884.jpg, 310 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\603709866_a97c7cfc72.jpg, 311 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\149244013_c529578289.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\17081114_79b9a27724.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\11381045_b352a47d8c.jpg, 312 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\20935278_9190345f6b.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\0013035.jpg, 313 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\540976476_844950623f.jpg, 314 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\24335309_c5ea483bb8.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\28847243_e79fe052cd.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\603711658_4c8cd2201e.jpg, 315 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\35558229_1fa4608a7a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\760526046_547e8b381f.jpg, 316 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\36439863_0bec9f554f.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\590318879_68cf112861.jpg, 317 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\45472593_bfd624f8dc.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\119785936_dd428e40c3.jpg, 318 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\586474709_ae436da045.jpg, 319 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\49375974_e28ba6f17e.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\5650366_e22b7e1065.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\421515404_e87569fd8b.jpg, 320 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\57264437_a19006872f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\10308379_1b6c72e180.jpg, 321 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\6240329_72c01e663e.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\36439863_0bec9f554f.jpg, 322 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\6240338_93729615ec.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\348291597_ee836fbb1a.jpg, 323 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\67270775_e9fdf77e9d.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\24335309_c5ea483bb8.jpg, 324 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\6743948_2b8c096dda.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\20935278_9190345f6b.jpg, 325 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\5650366_e22b7e1065.jpg, 326 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\69639610_95e0de17aa.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\7759525_1363d24e88.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\6240329_72c01e663e.jpg, 327 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\800px-Meat_eater_ant_qeen_excavating_hole.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\35558229_1fa4608a7a.jpg, 328 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\8124241_36b290d372.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\969455125_58c797ef17.jpg, 329 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\82852639_52b7f7f5e3.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\936182217_c4caa5222d.jpg, 330 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\8398478_50ef10c47a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\6240338_93729615ec.jpg, 331 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\94999827_36895faade.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\57264437_a19006872f.jpg, 332 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\ants\\9715481_b3cb4114ff.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\132478121_2a430adea2.jpg, 333 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2709775832_85b4b50a57.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\473618094_8ffdcab215.jpg, 334 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2710368626_cb42882dc8.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\149244013_c529578289.jpg, 335 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2717418782_bd83307d9f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\8124241_36b290d372.jpg, 336 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2722592222_258d473e17.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\7759525_1363d24e88.jpg, 337 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2728759455_ce9bb8cd7a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\6743948_2b8c096dda.jpg, 338 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\116570827_e9c126745d.jpg, 339 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2741763055_9a7bb00802.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2745389517_250a397f31.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\69639610_95e0de17aa.jpg, 340 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2751836205_6f7b5eff30.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\17081114_79b9a27724.jpg, 341 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\45472593_bfd624f8dc.jpg, 342 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2756397428_1d82a08807.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2765347790_da6cf6cb40.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\147542264_79506478c2.jpg, 343 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2781170484_5d61835d63.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\522104315_5d3cb2758e.jpg, 344 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2782079948_8d4e94a826.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\359928878_b3b418c728.jpg, 345 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\9715481_b3cb4114ff.jpg, 346 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2792000093_e8ae0718cf.jpg\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2801728106_833798c909.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\760568592_45a52c847f.jpg, 347 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2809496124_5f25b5946a.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\537309131_532bfa59ea.jpg, 348 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2815838190_0a9889d995.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\148715752_302c84f5a4.jpg, 349 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2822388965_f6dca2a275.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\8398478_50ef10c47a.jpg, 350 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2841437312_789699c740.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\94999827_36895faade.jpg, 351 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2861002136_52c7c6f708.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2728759455_ce9bb8cd7a.jpg, 352 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2883093452_7e3a1eb53f.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\800px-Meat_eater_ant_qeen_excavating_hole.jpg, 353 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2908916142_a7ac8b57a8.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\774440991_63a4aa0cbe.jpg, 354 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2959730355_416a18c63c.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2741763055_9a7bb00802.jpg, 355 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\2962405283_22718d9617.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2765347790_da6cf6cb40.jpg, 356 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\3006264892_30e9cced70.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2709775832_85b4b50a57.jpg, 357 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\3030189811_01d095b793.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2781170484_5d61835d63.jpg, 358 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\3030772428_8578335616.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2822388965_f6dca2a275.jpg, 359 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\3044402684_3853071a87.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\67270775_e9fdf77e9d.jpg, 360 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\3074585407_9854eb3153.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2959730355_416a18c63c.jpg, 361 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\3077452620_548c79fda0.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2861002136_52c7c6f708.jpg, 362 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\3079610310_ac2d0ae7bc.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2815838190_0a9889d995.jpg, 363 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\3090975720_71f12e6de4.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2782079948_8d4e94a826.jpg, 364 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\3100226504_c0d4f1e3f1.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\3074585407_9854eb3153.jpg, 365 files out of an estimated total of 397\n",
      "Uploading .\\train_dataset\\hymenoptera_data\\val\\bees\\abeja.jpg\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2745389517_250a397f31.jpg, 366 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2801728106_833798c909.jpg, 367 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\49375974_e28ba6f17e.jpg, 368 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2792000093_e8ae0718cf.jpg, 369 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\28847243_e79fe052cd.jpg, 370 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\3030189811_01d095b793.jpg, 371 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2883093452_7e3a1eb53f.jpg, 372 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2841437312_789699c740.jpg, 373 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\abeja.jpg, 374 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2751836205_6f7b5eff30.jpg, 375 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2717418782_bd83307d9f.jpg, 376 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\3079610310_ac2d0ae7bc.jpg, 377 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\3006264892_30e9cced70.jpg, 378 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\3100226504_c0d4f1e3f1.jpg, 379 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\509247772_2db2d01374.jpg, 380 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\478701318_bbd5e557b8.jpg, 381 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2908916142_a7ac8b57a8.jpg, 382 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\3044402684_3853071a87.jpg, 383 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2809496124_5f25b5946a.jpg, 384 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2962405283_22718d9617.jpg, 385 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2722592222_258d473e17.jpg, 386 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\3090975720_71f12e6de4.jpg, 387 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\3030772428_8578335616.jpg, 388 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2710368626_cb42882dc8.jpg, 389 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\ants\\82852639_52b7f7f5e3.jpg, 390 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\3077452620_548c79fda0.jpg, 391 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\val\\bees\\2756397428_1d82a08807.jpg, 392 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\873076652_eb098dab2d.jpg, 393 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\bees\\144098310_a4176fd54d.jpg, 394 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\test\\ants\\Nepenthes_rafflesiana_ant.jpg, 395 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\2551813042_8a070aeb2b.jpg, 396 files out of an estimated total of 397\n",
      "Uploaded .\\train_dataset\\hymenoptera_data\\train\\bees\\452462677_7be43af8ff.jpg, 397 files out of an estimated total of 397\n",
      "Uploaded 397 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_a3891672fdd5471cb2465528b4f97c2b"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "datastore.upload(src_dir = os.path.join('.', 'train_dataset'),\n",
    "                      target_path = 'train_dataset/image_dataset',\n",
    "                      overwrite = True,\n",
    "                      show_progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will register a dataset in the Azure Machine Learning Workspace as a file dataset. A file dataset can be mounted to the compute engine. When you mount a file system, you attach that file system to a directory (mount point) and make it available to the system. Because mounting load files at the time of processing, it is usually faster than download.\n",
    "Note: mounting is only available for Linux-based compute (DSVM/VM, AMLCompute, HDInsights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\dataprep\\api\\dataflow.py:720: UserWarning: Please install pyarrow>=0.11.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install azureml-dataprep[pandas].\n",
      "  warnings.warn('Please install pyarrow>=0.11.0 for improved performance of to_pandas_dataframe. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['/test/ants/1693954099_46d4c20605.jpg',\n",
       "       '/test/ants/1743840368_b5ccda82b7.jpg',\n",
       "       '/test/ants/1804095607_0341701e1c.jpg',\n",
       "       '/test/ants/1808777855_2a895621d7.jpg',\n",
       "       '/test/ants/1917341202_d00a7f9af5.jpg',\n",
       "       '/test/ants/1924473702_daa9aacdbe.jpg',\n",
       "       '/test/ants/2019439677_2db655d361.jpg',\n",
       "       '/test/ants/2039585088_c6f47c592e.jpg',\n",
       "       '/test/ants/2104709400_8831b4fc6f.jpg',\n",
       "       '/test/ants/2127908701_d49dc83c97.jpg',\n",
       "       '/test/ants/2191997003_379df31291.jpg',\n",
       "       '/test/ants/2211974567_ee4606b493.jpg',\n",
       "       '/test/ants/2219621907_47bc7cc6b0.jpg',\n",
       "       '/test/ants/2238242353_52c82441df.jpg',\n",
       "       '/test/ants/2255445811_dabcdf7258.jpg',\n",
       "       '/test/ants/2265824718_2c96f485da.jpg',\n",
       "       '/test/ants/2265825502_fff99cfd2d.jpg',\n",
       "       '/test/ants/2278278459_6b99605e50.jpg',\n",
       "       '/test/ants/2288450226_a6e96e8fdf.jpg',\n",
       "       '/test/ants/2288481644_83ff7e4572.jpg',\n",
       "       '/test/ants/2292213964_ca51ce4bef.jpg', '/test/ants/Ant-1818.jpg',\n",
       "       '/test/ants/Ant_1.jpg', '/test/ants/F.pergan.28(f).jpg',\n",
       "       '/test/ants/Hormiga.jpg', '/test/ants/MehdiabadiAnt2_600.jpg',\n",
       "       '/test/ants/Nepenthes_rafflesiana_ant.jpg',\n",
       "       '/test/ants/VietnameseAntMimicSpider.jpg',\n",
       "       '/test/ants/ant%20photos.jpg',\n",
       "       '/test/ants/ants-devouring-remains-of-large-dead-insect-on-red-tile-in-Stellenbosch-South-Africa-closeup-1-DHD.jpg',\n",
       "       '/test/ants/army-ants-red-picture.jpg',\n",
       "       '/test/ants/desert_ant.jpg', '/test/ants/formica.jpeg',\n",
       "       '/test/ants/hormiga_co_por.jpg', '/test/ants/kurokusa.jpg',\n",
       "       '/test/ants/swiss-army-ant.jpg', '/test/ants/termite-vs-ant.jpg',\n",
       "       '/test/ants/trap-jaw-ant-insect-bg.jpg',\n",
       "       '/test/bees/10870992_eebeeb3a12.jpg',\n",
       "       '/test/bees/129236073_0985e91c7d.jpg',\n",
       "       '/test/bees/132511197_0b86ad0fff.jpg',\n",
       "       '/test/bees/132826773_dbbcb117b9.jpg',\n",
       "       '/test/bees/144098310_a4176fd54d.jpg',\n",
       "       '/test/bees/149973093_da3c446268.jpg',\n",
       "       '/test/bees/150013791_969d9a968b.jpg',\n",
       "       '/test/bees/151594775_ee7dc17b60.jpg',\n",
       "       '/test/bees/151603988_2c6f7d14c7.jpg',\n",
       "       '/test/bees/152789693_220b003452.jpg',\n",
       "       '/test/bees/154600396_53e1252e52.jpg',\n",
       "       '/test/bees/16838648_415acd9e3f.jpg',\n",
       "       '/test/bees/17209602_fe5a5a746f.jpg',\n",
       "       '/test/bees/174142798_e5ad6d76e0.jpg',\n",
       "       '/test/bees/177677657_a38c97e572.jpg',\n",
       "       '/test/bees/181171681_c5a1a82ded.jpg',\n",
       "       '/test/bees/187130242_4593a4c610.jpg',\n",
       "       '/test/bees/196430254_46bd129ae7.jpg',\n",
       "       '/test/bees/196658222_3fffd79c67.jpg',\n",
       "       '/test/bees/198508668_97d818b6c4.jpg',\n",
       "       '/test/bees/203868383_0fcbb48278.jpg',\n",
       "       '/test/bees/205835650_e6f2614bee.jpg',\n",
       "       '/test/bees/208702903_42fb4d9748.jpg',\n",
       "       '/test/bees/21399619_3e61e5bb6f.jpg',\n",
       "       '/test/bees/26589803_5ba7000313.jpg',\n",
       "       '/test/bees/29494643_e3410f0d37.jpg',\n",
       "       '/test/bees/36900412_92b81831ad.jpg',\n",
       "       '/test/bees/39672681_1302d204d1.jpg',\n",
       "       '/test/bees/39747887_42df2855ee.jpg',\n",
       "       '/test/bees/44105569_16720a960c.jpg',\n",
       "       '/test/bees/54736755_c057723f64.jpg',\n",
       "       '/test/bees/57459255_752774f1b2.jpg',\n",
       "       '/test/bees/59798110_2b6a3c8031.jpg',\n",
       "       '/test/bees/65038344_52a45d090d.jpg',\n",
       "       '/test/bees/6a00d8341c630a53ef00e553d0beb18834-800wi.jpg',\n",
       "       '/test/bees/72100438_73de9f17af.jpg',\n",
       "       '/test/bees/85112639_6e860b0469.jpg',\n",
       "       '/test/bees/90179376_abc234e5f4.jpg',\n",
       "       '/test/bees/92663402_37f379e57a.jpg',\n",
       "       '/test/bees/95238259_98470c5b10.jpg',\n",
       "       '/test/bees/98391118_bdb1e80cce.jpg',\n",
       "       '/train/ants/1030023514_aad5c608f9.jpg',\n",
       "       '/train/ants/1053149811_f62a3410d3.jpg',\n",
       "       '/train/ants/1073564163_225a64f170.jpg',\n",
       "       '/train/ants/1095476100_3906d8afde.jpg',\n",
       "       '/train/ants/1099452230_d1949d3250.jpg',\n",
       "       '/train/ants/1119630822_cd325ea21a.jpg',\n",
       "       '/train/ants/1124525276_816a07c17f.jpg',\n",
       "       '/train/ants/1225872729_6f0856588f.jpg',\n",
       "       '/train/ants/1247887232_edcb61246c.jpg',\n",
       "       '/train/ants/1262751255_c56c042b7b.jpg',\n",
       "       '/train/ants/1262877379_64fcada201.jpg',\n",
       "       '/train/ants/1269756697_0bce92cdab.jpg',\n",
       "       '/train/ants/1286984635_5119e80de1.jpg',\n",
       "       '/train/ants/1337725712_2eb53cd742.jpg',\n",
       "       '/train/ants/1358854066_5ad8015f7f.jpg',\n",
       "       '/train/ants/1360291657_dc248c5eea.jpg',\n",
       "       '/train/ants/1368913450_e146e2fb6d.jpg',\n",
       "       '/train/ants/1440002809_b268d9a66a.jpg',\n",
       "       '/train/ants/1473187633_63ccaacea6.jpg',\n",
       "       '/train/ants/1489674356_09d48dde0a.jpg',\n",
       "       '/train/ants/150801003_3390b73135.jpg',\n",
       "       '/train/ants/150801171_cd86f17ed8.jpg',\n",
       "       '/train/ants/152286280_411648ec27.jpg',\n",
       "       '/train/ants/153320619_2aeb5fa0ee.jpg',\n",
       "       '/train/ants/153783656_85f9c3ac70.jpg',\n",
       "       '/train/ants/154124431_65460430f2.jpg',\n",
       "       '/train/ants/157401988_d0564a9d02.jpg',\n",
       "       '/train/ants/159515240_d5981e20d1.jpg',\n",
       "       '/train/ants/161076144_124db762d6.jpg',\n",
       "       '/train/ants/161292361_c16e0bf57a.jpg',\n",
       "       '/train/ants/162603798_40b51f1654.jpg',\n",
       "       '/train/ants/1660097129_384bf54490.jpg',\n",
       "       '/train/ants/167890289_dd5ba923f3.jpg',\n",
       "       '/train/ants/170652283_ecdaff5d1a.jpg',\n",
       "       '/train/ants/172772109_d0a8e15fb0.jpg',\n",
       "       '/train/ants/175998972.jpg',\n",
       "       '/train/ants/178538489_bec7649292.jpg',\n",
       "       '/train/ants/181942028_961261ef48.jpg',\n",
       "       '/train/ants/183260961_64ab754c97.jpg',\n",
       "       '/train/ants/188552436_605cc9b36b.jpg',\n",
       "       '/train/ants/196057951_63bf063b92.jpg',\n",
       "       '/train/ants/196757565_326437f5fe.jpg',\n",
       "       '/train/ants/201558278_fe4caecc76.jpg',\n",
       "       '/train/ants/201790779_527f4c0168.jpg',\n",
       "       '/train/ants/205398178_c395c5e460.jpg',\n",
       "       '/train/ants/207947948_3ab29d7207.jpg',\n",
       "       '/train/ants/208072188_f293096296.jpg',\n",
       "       '/train/ants/209615353_eeb38ba204.jpg',\n",
       "       '/train/ants/212100470_b485e7b7b9.jpg',\n",
       "       '/train/ants/224655713_3956f7d39a.jpg',\n",
       "       '/train/ants/226951206_d6bf946504.jpg',\n",
       "       '/train/ants/239161491_86ac23b0a3.jpg',\n",
       "       '/train/ants/245647475_9523dfd13e.jpg',\n",
       "       '/train/ants/255434217_1b2b3fe0a4.jpg',\n",
       "       '/train/ants/258217966_d9d90d18d3.jpg',\n",
       "       '/train/ants/263615709_cfb28f6b8e.jpg',\n",
       "       '/train/ants/275429470_b2d7d9290b.jpg',\n",
       "       '/train/ants/308196310_1db5ffa01b.jpg',\n",
       "       '/train/ants/318052216_84dff3f98a.jpg',\n",
       "       '/train/ants/319494379_648fb5a1c6.jpg',\n",
       "       '/train/ants/334167043_cbd1adaeb9.jpg',\n",
       "       '/train/ants/339670531_94b75ae47a.jpg',\n",
       "       '/train/ants/342438950_a3da61deab.jpg',\n",
       "       '/train/ants/374435068_7eee412ec4.jpg',\n",
       "       '/train/ants/382971067_0bfd33afe0.jpg',\n",
       "       '/train/ants/384191229_5779cf591b.jpg',\n",
       "       '/train/ants/386190770_672743c9a7.jpg',\n",
       "       '/train/ants/392382602_1b7bed32fa.jpg',\n",
       "       '/train/ants/403746349_71384f5b58.jpg',\n",
       "       '/train/ants/408393566_b5b694119b.jpg',\n",
       "       '/train/ants/412436937_4c2378efc2.jpg',\n",
       "       '/train/ants/424119020_6d57481dab.jpg',\n",
       "       '/train/ants/424873399_47658a91fb.jpg',\n",
       "       '/train/ants/436944325_d4925a38c7.jpg',\n",
       "       '/train/ants/445356866_6cb3289067.jpg',\n",
       "       '/train/ants/450057712_771b3bfc91.jpg',\n",
       "       '/train/ants/459442412_412fecf3fe.jpg',\n",
       "       '/train/ants/459694881_ac657d3187.jpg',\n",
       "       '/train/ants/460372577_f2f6a8c9fc.jpg',\n",
       "       '/train/ants/460874319_0a45ab4d05.jpg',\n",
       "       '/train/ants/466430434_4000737de9.jpg',\n",
       "       '/train/ants/470127037_513711fd21.jpg',\n",
       "       '/train/ants/470127071_8b8ee2bd74.jpg',\n",
       "       '/train/ants/474806473_ca6caab245.jpg',\n",
       "       '/train/ants/475961153_b8c13fd405.jpg',\n",
       "       '/train/ants/477437164_bc3e6e594a.jpg',\n",
       "       '/train/ants/484293231_e53cfc0c89.jpg',\n",
       "       '/train/ants/488272201_c5aa281348.jpg',\n",
       "       '/train/ants/502717153_3e4865621a.jpg',\n",
       "       '/train/ants/506249802_207cd979b4.jpg',\n",
       "       '/train/ants/506249836_717b73f540.jpg',\n",
       "       '/train/ants/512164029_c0a66b8498.jpg',\n",
       "       '/train/ants/512863248_43c8ce579b.jpg',\n",
       "       '/train/ants/518746016_bcc28f8b5b.jpg',\n",
       "       '/train/ants/518773929_734dbc5ff4.jpg',\n",
       "       '/train/ants/522163566_fec115ca66.jpg',\n",
       "       '/train/ants/522415432_2218f34bf8.jpg',\n",
       "       '/train/ants/531979952_bde12b3bc0.jpg',\n",
       "       '/train/ants/533848102_70a85ad6dd.jpg',\n",
       "       '/train/ants/535522953_308353a07c.jpg',\n",
       "       '/train/ants/540543309_ddbb193ee5.jpg',\n",
       "       '/train/ants/540889389_48bb588b21.jpg',\n",
       "       '/train/ants/541630764_dbd285d63c.jpg',\n",
       "       '/train/ants/543417860_b14237f569.jpg',\n",
       "       '/train/ants/560966032_988f4d7bc4.jpg',\n",
       "       '/train/ants/562589509_7e55469b97.jpg',\n",
       "       '/train/ants/573151833_ebbc274b77.jpg',\n",
       "       '/train/ants/649026570_e58656104b.jpg',\n",
       "       '/train/ants/649407494_9b6bc4949f.jpg',\n",
       "       '/train/ants/662541407_ff8db781e7.jpg',\n",
       "       '/train/ants/684133190_35b62c0c1d.jpg',\n",
       "       '/train/ants/707895295_009cf23188.jpg',\n",
       "       '/train/ants/751649788_78dd7d16ce.jpg',\n",
       "       '/train/ants/768870506_8f115d3d37.jpg',\n",
       "       '/train/ants/795000156_a9900a4a71.jpg',\n",
       "       '/train/ants/822537660_caf4ba5514.jpg',\n",
       "       '/train/ants/841049277_b28e58ad05.jpg',\n",
       "       '/train/ants/854534770_31f6156383.jpg',\n",
       "       '/train/ants/886401651_f878e888cd.jpg',\n",
       "       '/train/ants/892108839_f1aad4ca46.jpg',\n",
       "       '/train/ants/892676922_4ab37dce07.jpg',\n",
       "       '/train/ants/938946700_ca1c669085.jpg',\n",
       "       '/train/ants/957233405_25c1d1187b.jpg',\n",
       "       '/train/ants/998118368_6ac1d91f81.jpg',\n",
       "       '/train/bees/1032546534_06907fe3b3.jpg',\n",
       "       '/train/bees/1092977343_cb42b38d62.jpg',\n",
       "       '/train/bees/1093831624_fb5fbe2308.jpg',\n",
       "       '/train/bees/1097045929_1753d1c765.jpg',\n",
       "       '/train/bees/1181173278_23c36fac71.jpg',\n",
       "       '/train/bees/1232245714_f862fbe385.jpg',\n",
       "       '/train/bees/1295655112_7813f37d21.jpg',\n",
       "       '/train/bees/1297972485_33266a18d9.jpg',\n",
       "       '/train/bees/1328423762_f7a88a8451.jpg',\n",
       "       '/train/bees/1355974687_1341c1face.jpg',\n",
       "       '/train/bees/1486120850_490388f84b.jpg',\n",
       "       '/train/bees/1508176360_2972117c9d.jpg',\n",
       "       '/train/bees/1519368889_4270261ee3.jpg',\n",
       "       '/train/bees/1691282715_0addfdf5e8.jpg',\n",
       "       '/train/bees/1799726602_8580867f71.jpg',\n",
       "       '/train/bees/1799729694_0c40101071.jpg',\n",
       "       '/train/bees/1807583459_4fe92b3133.jpg',\n",
       "       '/train/bees/2031225713_50ed499635.jpg',\n",
       "       '/train/bees/2037437624_2d7bce461f.jpg',\n",
       "       '/train/bees/2053200300_8911ef438a.jpg',\n",
       "       '/train/bees/2060668999_e11edb10d0.jpg',\n",
       "       '/train/bees/2086294791_6f3789d8a6.jpg',\n",
       "       '/train/bees/2103637821_8d26ee6b90.jpg',\n",
       "       '/train/bees/2104135106_a65eede1de.jpg',\n",
       "       '/train/bees/215512424_687e1e0821.jpg',\n",
       "       '/train/bees/2173503984_9c6aaaa7e2.jpg',\n",
       "       '/train/bees/220376539_20567395d8.jpg',\n",
       "       '/train/bees/2227611847_ec72d40403.jpg',\n",
       "       '/train/bees/224841383_d050f5f510.jpg',\n",
       "       '/train/bees/2321139806_d73d899e66.jpg',\n",
       "       '/train/bees/2321144482_f3785ba7b2.jpg',\n",
       "       '/train/bees/2330918208_8074770c20.jpg',\n",
       "       '/train/bees/2345177635_caf07159b3.jpg',\n",
       "       '/train/bees/2358061370_9daabbd9ac.jpg',\n",
       "       '/train/bees/2364597044_3c3e3fc391.jpg',\n",
       "       '/train/bees/238161922_55fa9a76ae.jpg',\n",
       "       '/train/bees/2384149906_2cd8b0b699.jpg',\n",
       "       '/train/bees/2397446847_04ef3cd3e1.jpg',\n",
       "       '/train/bees/2405441001_b06c36fa72.jpg',\n",
       "       '/train/bees/2407809945_fb525ef54d.jpg',\n",
       "       '/train/bees/2415414155_1916f03b42.jpg',\n",
       "       '/train/bees/2438480600_40a1249879.jpg',\n",
       "       '/train/bees/2444778727_4b781ac424.jpg',\n",
       "       '/train/bees/2445215254_51698ff797.jpg',\n",
       "       '/train/bees/2452236943_255bfd9e58.jpg',\n",
       "       '/train/bees/2457841282_7867f16639.jpg',\n",
       "       '/train/bees/2467959963_a7831e9ff0.jpg',\n",
       "       '/train/bees/2470492902_3572c90f75.jpg',\n",
       "       '/train/bees/2470492904_837e97800d.jpg',\n",
       "       '/train/bees/2477324698_3d4b1b1cab.jpg',\n",
       "       '/train/bees/2477349551_e75c97cf4d.jpg',\n",
       "       '/train/bees/2478216347_535c8fe6d7.jpg',\n",
       "       '/train/bees/2486729079_62df0920be.jpg',\n",
       "       '/train/bees/2486746709_c43cec0e42.jpg',\n",
       "       '/train/bees/2493379287_4100e1dacc.jpg',\n",
       "       '/train/bees/2495722465_879acf9d85.jpg',\n",
       "       '/train/bees/2501530886_e20952b97d.jpg',\n",
       "       '/train/bees/2506114833_90a41c5267.jpg',\n",
       "       '/train/bees/2509402554_31821cb0b6.jpg',\n",
       "       '/train/bees/2525379273_dcb26a516d.jpg',\n",
       "       '/train/bees/2528444139_fa728b0f5b.jpg',\n",
       "       '/train/bees/2538361678_9da84b77e3.jpg',\n",
       "       '/train/bees/2551813042_8a070aeb2b.jpg',\n",
       "       '/train/bees/2580598377_a4caecdb54.jpg',\n",
       "       '/train/bees/2601176055_8464e6aa71.jpg',\n",
       "       '/train/bees/2610833167_79bf0bcae5.jpg',\n",
       "       '/train/bees/2610838525_fe8e3cae47.jpg',\n",
       "       '/train/bees/2617161745_fa3ebe85b4.jpg',\n",
       "       '/train/bees/2625499656_e3415e374d.jpg',\n",
       "       '/train/bees/2634617358_f32fd16bea.jpg',\n",
       "       '/train/bees/2638074627_6b3ae746a0.jpg',\n",
       "       '/train/bees/2645107662_b73a8595cc.jpg',\n",
       "       '/train/bees/2651621464_a2fa8722eb.jpg',\n",
       "       '/train/bees/2652877533_a564830cbf.jpg',\n",
       "       '/train/bees/266644509_d30bb16a1b.jpg',\n",
       "       '/train/bees/2668391343_45e272cd07.jpg',\n",
       "       '/train/bees/2670536155_c170f49cd0.jpg',\n",
       "       '/train/bees/2683605182_9d2a0c66cf.jpg',\n",
       "       '/train/bees/2685605303_9eed79d59d.jpg',\n",
       "       '/train/bees/2702408468_d9ed795f4f.jpg',\n",
       "       '/train/bees/2704348794_eb5d5178c2.jpg',\n",
       "       '/train/bees/2707440199_cd170bd512.jpg',\n",
       "       '/train/bees/272986700_d4d4bf8c4b.jpg',\n",
       "       '/train/bees/279113587_b4843db199.jpg',\n",
       "       '/train/bees/290082189_f66cb80bfc.jpg',\n",
       "       '/train/bees/296565463_d07a7bed96.jpg',\n",
       "       '/train/bees/342758693_c56b89b6b6.jpg',\n",
       "       '/train/bees/348291597_ee836fbb1a.jpg',\n",
       "       '/train/bees/350436573_41f4ecb6c8.jpg',\n",
       "       '/train/bees/353266603_d3eac7e9a0.jpg',\n",
       "       '/train/bees/354167719_22dca13752.jpg',\n",
       "       '/train/bees/359928878_b3b418c728.jpg',\n",
       "       '/train/bees/365759866_b15700c59b.jpg',\n",
       "       '/train/bees/372228424_16da1f8884.jpg',\n",
       "       '/train/bees/400262091_701c00031c.jpg',\n",
       "       '/train/bees/416144384_961c326481.jpg',\n",
       "       '/train/bees/421515404_e87569fd8b.jpg',\n",
       "       '/train/bees/444532809_9e931e2279.jpg',\n",
       "       '/train/bees/446296270_d9e8b93ecf.jpg',\n",
       "       '/train/bees/452462677_7be43af8ff.jpg',\n",
       "       '/train/bees/452462695_40a4e5b559.jpg',\n",
       "       '/train/bees/456097971_860949c4fc.jpg',\n",
       "       '/train/bees/457457145_5f86eb7e9c.jpg',\n",
       "       '/train/bees/464594019_1b24a28bb1.jpg',\n",
       "       '/train/bees/465133211_80e0c27f60.jpg',\n",
       "       '/train/bees/469333327_358ba8fe8a.jpg',\n",
       "       '/train/bees/472288710_2abee16fa0.jpg',\n",
       "       '/train/bees/473618094_8ffdcab215.jpg',\n",
       "       '/train/bees/476347960_52edd72b06.jpg',\n",
       "       '/train/bees/478701318_bbd5e557b8.jpg',\n",
       "       '/train/bees/485743562_d8cc6b8f73.jpg',\n",
       "       '/train/bees/507288830_f46e8d4cb2.jpg',\n",
       "       '/train/bees/509247772_2db2d01374.jpg',\n",
       "       '/train/bees/513545352_fd3e7c7c5d.jpg',\n",
       "       '/train/bees/522104315_5d3cb2758e.jpg',\n",
       "       '/train/bees/537309131_532bfa59ea.jpg',\n",
       "       '/train/bees/540976476_844950623f.jpg',\n",
       "       '/train/bees/576452297_897023f002.jpg',\n",
       "       '/train/bees/586041248_3032e277a9.jpg',\n",
       "       '/train/bees/586474709_ae436da045.jpg',\n",
       "       '/train/bees/590318879_68cf112861.jpg',\n",
       "       '/train/bees/603709866_a97c7cfc72.jpg',\n",
       "       '/train/bees/603711658_4c8cd2201e.jpg',\n",
       "       '/train/bees/759745145_e8bc776ec8.jpg',\n",
       "       '/train/bees/760526046_547e8b381f.jpg',\n",
       "       '/train/bees/760568592_45a52c847f.jpg',\n",
       "       '/train/bees/774440991_63a4aa0cbe.jpg',\n",
       "       '/train/bees/873076652_eb098dab2d.jpg',\n",
       "       '/train/bees/936182217_c4caa5222d.jpg',\n",
       "       '/train/bees/969455125_58c797ef17.jpg', '/val/ants/0013035.jpg',\n",
       "       '/val/ants/10308379_1b6c72e180.jpg',\n",
       "       '/val/ants/11381045_b352a47d8c.jpg',\n",
       "       '/val/ants/116570827_e9c126745d.jpg',\n",
       "       '/val/ants/119785936_dd428e40c3.jpg',\n",
       "       '/val/ants/132478121_2a430adea2.jpg',\n",
       "       '/val/ants/147542264_79506478c2.jpg',\n",
       "       '/val/ants/148715752_302c84f5a4.jpg',\n",
       "       '/val/ants/149244013_c529578289.jpg',\n",
       "       '/val/ants/17081114_79b9a27724.jpg',\n",
       "       '/val/ants/20935278_9190345f6b.jpg',\n",
       "       '/val/ants/24335309_c5ea483bb8.jpg',\n",
       "       '/val/ants/28847243_e79fe052cd.jpg',\n",
       "       '/val/ants/35558229_1fa4608a7a.jpg',\n",
       "       '/val/ants/36439863_0bec9f554f.jpg',\n",
       "       '/val/ants/45472593_bfd624f8dc.jpg',\n",
       "       '/val/ants/49375974_e28ba6f17e.jpg',\n",
       "       '/val/ants/5650366_e22b7e1065.jpg',\n",
       "       '/val/ants/57264437_a19006872f.jpg',\n",
       "       '/val/ants/6240329_72c01e663e.jpg',\n",
       "       '/val/ants/6240338_93729615ec.jpg',\n",
       "       '/val/ants/67270775_e9fdf77e9d.jpg',\n",
       "       '/val/ants/6743948_2b8c096dda.jpg',\n",
       "       '/val/ants/69639610_95e0de17aa.jpg',\n",
       "       '/val/ants/7759525_1363d24e88.jpg',\n",
       "       '/val/ants/800px-Meat_eater_ant_qeen_excavating_hole.jpg',\n",
       "       '/val/ants/8124241_36b290d372.jpg',\n",
       "       '/val/ants/82852639_52b7f7f5e3.jpg',\n",
       "       '/val/ants/8398478_50ef10c47a.jpg',\n",
       "       '/val/ants/94999827_36895faade.jpg',\n",
       "       '/val/ants/9715481_b3cb4114ff.jpg',\n",
       "       '/val/bees/2709775832_85b4b50a57.jpg',\n",
       "       '/val/bees/2710368626_cb42882dc8.jpg',\n",
       "       '/val/bees/2717418782_bd83307d9f.jpg',\n",
       "       '/val/bees/2722592222_258d473e17.jpg',\n",
       "       '/val/bees/2728759455_ce9bb8cd7a.jpg',\n",
       "       '/val/bees/2741763055_9a7bb00802.jpg',\n",
       "       '/val/bees/2745389517_250a397f31.jpg',\n",
       "       '/val/bees/2751836205_6f7b5eff30.jpg',\n",
       "       '/val/bees/2756397428_1d82a08807.jpg',\n",
       "       '/val/bees/2765347790_da6cf6cb40.jpg',\n",
       "       '/val/bees/2781170484_5d61835d63.jpg',\n",
       "       '/val/bees/2782079948_8d4e94a826.jpg',\n",
       "       '/val/bees/2792000093_e8ae0718cf.jpg',\n",
       "       '/val/bees/2801728106_833798c909.jpg',\n",
       "       '/val/bees/2809496124_5f25b5946a.jpg',\n",
       "       '/val/bees/2815838190_0a9889d995.jpg',\n",
       "       '/val/bees/2822388965_f6dca2a275.jpg',\n",
       "       '/val/bees/2841437312_789699c740.jpg',\n",
       "       '/val/bees/2861002136_52c7c6f708.jpg',\n",
       "       '/val/bees/2883093452_7e3a1eb53f.jpg',\n",
       "       '/val/bees/2908916142_a7ac8b57a8.jpg',\n",
       "       '/val/bees/2959730355_416a18c63c.jpg',\n",
       "       '/val/bees/2962405283_22718d9617.jpg',\n",
       "       '/val/bees/3006264892_30e9cced70.jpg',\n",
       "       '/val/bees/3030189811_01d095b793.jpg',\n",
       "       '/val/bees/3030772428_8578335616.jpg',\n",
       "       '/val/bees/3044402684_3853071a87.jpg',\n",
       "       '/val/bees/3074585407_9854eb3153.jpg',\n",
       "       '/val/bees/3077452620_548c79fda0.jpg',\n",
       "       '/val/bees/3079610310_ac2d0ae7bc.jpg',\n",
       "       '/val/bees/3090975720_71f12e6de4.jpg',\n",
       "       '/val/bees/3100226504_c0d4f1e3f1.jpg', '/val/bees/abeja.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "file_dataset = Dataset.File.from_files(path = [(datastore, 'train_dataset/image_dataset/hymenoptera_data')])\n",
    "file_dataset = file_dataset.register(workspace=ws,\n",
    "                                     name='hymenoptera_data',\n",
    "                                     description='hymenoptera training dataset',\n",
    "                                     create_new_version = True)\n",
    "\n",
    "file_dataset.to_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Compute Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample, we want to train a simple scikit-learn model on a remote compute engine on Azure. To do so, we first must create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target).\n",
    "\n",
    "In this challenge, we want to use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource. Once this is created, you are ready to train on your remote compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TASK:** Create a machine learning compute target.\n",
    "\n",
    "Create an Azure Machine Learning Compute cluster and folow the steps one to four.\n",
    "1. Check whether the cluster with the given name already exists.\n",
    "2. Create the configuration (this step is local and only takes a second). Use the SKU `STANDARD_D2_V2` and a maximum of 4 nodes.\n",
    "3. Create the cluster (this step will take about 20 seconds)\n",
    "4. Provision the VMs to bring the cluster to the initial size. This step will take about 3-5 minutes and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.computetarget?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-01-16T12:43:07.646000+00:00', 'errors': None, 'creationTime': '2019-02-12T12:37:37.681874+00:00', 'modifiedTime': '2020-01-13T16:38:38.837729+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a project directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER_NAME = 'train_new'\n",
    "TRAIN_FILE_NAME = 'train.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a training script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will need to create your training scripts in your project folder. This will be done in the next step. In practice, you should be able to take any custom training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "If you would like to use Azure ML's [tracking and metrics](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#metrics) capabilities, you will have to add a small amount of Azure ML code inside your training script.\n",
    "\n",
    "In `train_iris.py`, we will log some metrics to our Azure ML run. To do so, we will access the Azure ML Run object within the script:\n",
    "\n",
    "```python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "\n",
    "Further within `train_iris.py`, we log the kernel and penalty parameters, and the highest accuracy the model achieves:\n",
    "\n",
    "```python\n",
    "run.log('Kernel type', np.string(args.kernel))\n",
    "run.log('Penalty', np.float(args.penalty))\n",
    "\n",
    "run.log('Accuracy', np.float(accuracy))\n",
    "```\n",
    "\n",
    "These run metrics will become particularly important when we begin hyperparameter tuning our model in the \"Tune model hyperparameters\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: The training script below misses to log a few of the metrics. Find the `???` and complete the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://pytorch.org/docs/stable/torchvision/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $TRAIN_FOLDER_NAME/$TRAIN_FILE_NAME\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import onnx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import utils\n",
    "\n",
    "from azureml.core import Dataset, Run\n",
    "run = Run.get_context() # get the Azure ML run object\n",
    "\n",
    "\n",
    "def train_one_epoch(model, criterion, optimizer, data_loader, device, epoch):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create objects for tracking parameters\n",
    "    img_processing = utils.AverageMeter()\n",
    "    batch_time = utils.AverageMeter()\n",
    "    losses = utils.AverageMeter()\n",
    "    accuracies1 = utils.AverageMeter()\n",
    "    accuracies5 = utils.AverageMeter()\n",
    "    lr = utils.AverageMeter()\n",
    "    \n",
    "    # Put model in train mode\n",
    "    print('Model in training state')\n",
    "    model.train()\n",
    "\n",
    "    for i, (image, target) in enumerate(data_loader):\n",
    "        print('Iteration {0}'.format(i))\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure accuracy and loss\n",
    "        acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "        batch_size = image.shape[0]\n",
    "        losses.update(val=loss.item(), n=batch_size)\n",
    "        accuracies1.update(val=acc1.item(), n=batch_size)\n",
    "        accuracies5.update(val=acc5.item(), n=batch_size)\n",
    "        batch_time.update(val=time.time() - start_time)\n",
    "        img_processing.update(val=batch_size / (time.time() - start_time))\n",
    "        lr.update(val=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "        # Log metrics to Azure ML\n",
    "        run.log(name='train_loss', value=loss.item())\n",
    "        run.log(name='train_acc1', value=acc1.item())\n",
    "        run.log(name='train_acc5', value=acc5.item())\n",
    "        run.log(name='train_imgs/s', value=batch_size / (time.time() - start_time))\n",
    "        run.log(name='train_lr', value=optimizer.param_groups[0][\"lr\"])\n",
    "    \n",
    "    # Synchronize AverageMeters between processes --> leads to non working state in single node run\n",
    "    #img_processing.synchronize_between_processes(device=device)\n",
    "    #losses.synchronize_between_processes(device=device)\n",
    "    #accuracies1.synchronize_between_processes(device=device)\n",
    "    #accuracies5.synchronize_between_processes(device=device)\n",
    "\n",
    "    # Log metrics to Azure ML\n",
    "    run.log(name='train_loss_avg', value=losses.avg)\n",
    "    run.log(name='train_acc1_avg', value=accuracies1.avg)\n",
    "    run.log(name='train_acc5_avg', value=accuracies5.avg)\n",
    "    run.log(name='train_imgs/s_avg', value=img_processing.avg)\n",
    "\n",
    "    print('[Training] Epoch {epoch} Acc@1 {accuracies1.avg:.3f} Acc@5 {accuracies5.avg:.3f} Loss {losses.avg:.3f} Took {time}'\n",
    "          .format(epoch=epoch, accuracies1=accuracies1, accuracies5=accuracies5, losses=losses, time=(time.time()-start_time)))\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, data_loader, device, epoch):\n",
    "    # Create objects for tracking parameters\n",
    "    losses = utils.AverageMeter()\n",
    "    accuracies1 = utils.AverageMeter()\n",
    "    accuracies5 = utils.AverageMeter()\n",
    "    \n",
    "    # Put model in eval mode \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, target) in enumerate(data_loader):\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Measure accuracy and loss\n",
    "            acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "            batch_size = image.shape[0]\n",
    "            losses.update(val=loss.item(), n=batch_size)\n",
    "            accuracies1.update(val=acc1.item(), n=batch_size)\n",
    "            accuracies5.update(val=acc5.item(), n=batch_size)\n",
    "\n",
    "            # Log metrics to Azure ML\n",
    "            run.log(name='val_loss', value=loss.item())\n",
    "            run.log(name='val_acc1', value=acc1.item())\n",
    "            run.log(name='val_acc5', value=acc5.item())\n",
    "    \n",
    "    # Synchronize AverageMeters between processes --> leads to non working state in single node run\n",
    "    #losses.synchronize_between_processes(device=device)\n",
    "    #accuracies1.synchronize_between_processes(device=device)\n",
    "    #accuracies5.synchronize_between_processes(device=device)\n",
    "\n",
    "    # Log metrics to Azure ML\n",
    "    run.log(name='val_loss_avg', value=losses.avg)\n",
    "    run.log(name='val_acc1_avg', value=accuracies1.avg)\n",
    "    run.log(name='val_acc5_avg', value=accuracies5.avg)\n",
    "\n",
    "    print('[Validation] Epoch {epoch} Acc@1 {accuracies1.avg:.3f} Acc@5 {accuracies5.avg:.3f} Loss {losses.avg:.3f}'\n",
    "          .format(epoch=epoch, accuracies1=accuracies1, accuracies5=accuracies5, losses=losses))\n",
    "\n",
    "\n",
    "def load_data(traindir, valdir, distributed, input_size):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Load training data\n",
    "    print('Loading training data')\n",
    "    st = time.time()\n",
    "    dataset = torchvision.datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    print('Took {0}'.format(time.time() - st))\n",
    "\n",
    "    # Load validation data\n",
    "    print('Loading validation data')\n",
    "    dataset_test = torchvision.datasets.ImageFolder(\n",
    "        valdir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(input_size + 32),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    \n",
    "    # Create data sampler\n",
    "    print('Creating data sampler')\n",
    "    if distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "        test_sampler = torch.utils.data.distributed.DistributedSampler(dataset_test)\n",
    "    else:\n",
    "        train_sampler = None #torch.utils.data.RandomSampler(dataset) --> leads to non working state in single node run\n",
    "        test_sampler = None #torch.utils.data.SequentialSampler(dataset_test) --> leads to non working state in single node run\n",
    "\n",
    "    return dataset, dataset_test, train_sampler, test_sampler\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    print(args)\n",
    "\n",
    "    # Create output directory\n",
    "    print('Create output dir and paths')\n",
    "    if args.output_dir:\n",
    "        utils.mkdir(path=os.path.join('.', args.output_dir))\n",
    "    train_dir = os.path.join(args.data_path, 'train')\n",
    "    val_dir = os.path.join(args.data_path, 'val')\n",
    "    num_classes = len(train_dir)\n",
    "    \n",
    "    # Initialize distributed mode\n",
    "    print('Initialize distributed mode')\n",
    "    utils.init_distributed_mode(args=args)\n",
    "\n",
    "    # Create model\n",
    "    print('Create model')\n",
    "    model, input_size, params_to_update = utils.initialize_model(num_classes=num_classes, args=args)\n",
    "    \n",
    "    # Load data\n",
    "    print('Load data')\n",
    "    dataset, dataset_test, train_sampler, test_sampler = load_data(traindir=train_dir,\n",
    "                                                                   valdir=val_dir,\n",
    "                                                                   distributed=args.distributed,\n",
    "                                                                   input_size=input_size)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=args.batch_size,\n",
    "                                              sampler=train_sampler,\n",
    "                                              num_workers=args.workers,\n",
    "                                              shuffle=(train_sampler is None),\n",
    "                                              pin_memory=True)\n",
    "    data_loader_test = torch.utils.data.DataLoader(dataset_test,\n",
    "                                                   batch_size=args.batch_size,\n",
    "                                                   sampler=test_sampler, \n",
    "                                                   num_workers=args.workers,\n",
    "                                                   shuffle=(test_sampler is None),\n",
    "                                                   pin_memory=True)\n",
    "    \n",
    "    # Create criterion\n",
    "    print('Creating criterion')\n",
    "    criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "    # Create optimizer\n",
    "    print('Creating optimizer')\n",
    "    optimizer = torch.optim.SGD(\n",
    "        params_to_update,\n",
    "        lr=args.lr,\n",
    "        momentum=args.momentum,\n",
    "        weight_decay=args.weight_decay)\n",
    "    \n",
    "    # Create lr scheduler\n",
    "    print('Creating lr scheduler')\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=args.lr_step_size,\n",
    "        gamma=args.lr_gamma)\n",
    "    \n",
    "    # Resume from checkpoint\n",
    "    if args.resume:\n",
    "        print('Resuming from checkpoint {0}')\n",
    "        checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "        model.module.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "        args.start_epoch = checkpoint['epoch'] + 1\n",
    "    \n",
    "    if args.test_only:\n",
    "        # Test script only\n",
    "        print('Testing only')\n",
    "        evaluate(model, criterion, data_loader_test, device=args.device, epoch=0)\n",
    "\n",
    "    else:\n",
    "        # Train model\n",
    "        print('Start training')\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(args.start_epoch, args.epochs):\n",
    "            #if args.distributed: --> leads to non working state in single node run\n",
    "            #    train_sampler.set_epoch(epoch)\n",
    "            print('Epoch {0}'.format(epoch))\n",
    "\n",
    "            # Train one epoch\n",
    "            train_one_epoch(model, criterion, optimizer, data_loader, args.device, epoch)\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            # Evauluate on val data\n",
    "            evaluate(model, criterion, data_loader_test, args.device, epoch)\n",
    "\n",
    "            # Save checkpoints after each epoch\n",
    "            if args.output_dir:\n",
    "                checkpoint = {\n",
    "                    'model': model.module.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'args': args}\n",
    "                utils.save_on_master(\n",
    "                    checkpoint,\n",
    "                    os.path.join(args.output_dir, 'model_{}.pth'.format(epoch)))\n",
    "                utils.save_on_master(\n",
    "                    checkpoint,\n",
    "                    os.path.join(args.output_dir, 'checkpoint.pth'))\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print('Training time {}'.format(total_time_str))\n",
    "    \n",
    "    # Save model as pt and ONNX\n",
    "    if isinstance(model, torch.nn.DataParallel) or isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "        model = model.module\n",
    "    dummy_input = torch.randn(args.batch_size, 3, input_size, input_size, requires_grad=True, device=args.device)\n",
    "    torch.save(model, os.path.join(args.output_dir, 'model.pt'))\n",
    "    torch.onnx.export(model,\n",
    "                      dummy_input,\n",
    "                      os.path.join(args.output_dir, 'model.onnx'),\n",
    "                      export_params=True,\n",
    "                      opset_version=10,\n",
    "                      do_constant_folding=True,\n",
    "                      verbose=True,\n",
    "                      input_names = ['input'],\n",
    "                      output_names = ['output'],\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "    \n",
    "    # Check ONNX model\n",
    "    print('Checking ONNX model')\n",
    "    onnx_model = onnx.load(os.path.join(args.output_dir, 'model.onnx'))\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Classification Training')\n",
    "    \n",
    "    # Training parameters\n",
    "    parser.add_argument('--data-path', dest='data_path', default='/tmp/dataset/',\n",
    "                        help='dataset path')\n",
    "    parser.add_argument('--dataset-name', dest='dataset_name', default=None,\n",
    "                        help='dataset name')\n",
    "    parser.add_argument('--model', dest='model', default='resnet18',\n",
    "                        help='model name')\n",
    "    parser.add_argument('--device', dest='device', default='cuda',\n",
    "                        help='device')\n",
    "    parser.add_argument('-b', '--batch-size', dest='batch_size', default=32, type=int,\n",
    "                        help='input batch size for training (default: 32)')\n",
    "    parser.add_argument('--epochs', dest='epochs', default=10, type=int, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('-j', '--workers', dest='workers', default=16, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 16)')\n",
    "    parser.add_argument('--lr', dest='lr', default=0.01, type=float,\n",
    "                        help='initial learning rate (default 0.01)')\n",
    "    parser.add_argument('--momentum', dest='momentum', default=0.9, type=float, metavar='M',\n",
    "                        help='SGD momentum (default 0.9)')\n",
    "    parser.add_argument('--wd', '--weight-decay', dest='weight_decay', default=1e-4, type=float, metavar='W',\n",
    "                        help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument('--lr-step-size', dest='lr_step_size', default=30, type=int,\n",
    "                        help='decrease lr every step-size epochs')\n",
    "    parser.add_argument('--lr-gamma', dest='lr_gamma', default=0.1, type=float,\n",
    "                        help='decrease lr by a factor of lr-gamma')\n",
    "    parser.add_argument('--output-dir', dest='output_dir', default='outputs',\n",
    "                        help='path where to save')\n",
    "    parser.add_argument('--resume', dest='resume', default='',\n",
    "                        help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', dest='start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--test-only', dest='test_only', action='store_true',\n",
    "                        help='Only test the model')\n",
    "    parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                        help='Use pre-trained models from torchvision')\n",
    "    parser.add_argument('--finetuning', dest='finetuning', action='store_true',\n",
    "                        help='Finetune only last layer of CNN')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    \n",
    "    # Distributed training parameters\n",
    "    parser.add_argument('--world-size', dest='world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--dist-backend', dest='dist_backend', default='nccl', type=str,\n",
    "                        help='distributed backend')\n",
    "    parser.add_argument('--dist-url', dest='dist_url', type=str,\n",
    "                        help='url used to set up distributed training')\n",
    "    parser.add_argument('--rank', dest='rank', default=-1, type=int,\n",
    "                        help='rank of the worker')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load data and checkpoint path from run\n",
    "    try:\n",
    "        args.data_path = run.input_datasets[args.dataset_name]\n",
    "        print('Loaded registered dataset')\n",
    "    except:\n",
    "        print('Could not find registered dataset. Loading default data path.')\n",
    "    try:\n",
    "        args.resume = run.input_datasets[args.resume]\n",
    "        print('Loaded checkpoint path')\n",
    "    except:\n",
    "        args.resume = None\n",
    "        print('Could not find checkpoint path')\n",
    "    \n",
    "    # set distributed mode\n",
    "    args.distributed = args.world_size >= 2\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args=args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An *Experiment* is a logical container in an Azure ML Workspace that represents a collection of trials (individual model runs). It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Fill in the missing values below to create a new experiment in your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name='ch3-pytorch_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An estimator object is used to submit the run. Azure Machine Learning has pre-configured estimators for common machine learning frameworks, as well as generic Estimator. Create a generic estimator for by specifying\n",
    "\n",
    "- The name of the estimator object, est\n",
    "- The directory that contains your scripts. All the files in this directory are uploaded into the cluster nodes for execution.\n",
    "- The training script name, train_titanic.py\n",
    "- The input Dataset for training\n",
    "- The compute target. In this case you will use the AmlCompute you created\n",
    "- The environment definition for the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Complete the estimator creation below.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.estimator.estimator?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch, Nccl\n",
    "\n",
    "# distributed run with Nccl backend\n",
    "script_params = {\n",
    "    '--dataset-name': 'hymenoptera_data',\n",
    "    '--dist-backend': 'nccl',\n",
    "    '--dist-url': '$AZ_BATCHAI_PYTORCH_INIT_METHOD',\n",
    "    '--rank': '$AZ_BATCHAI_TASK_INDEX',\n",
    "    '--world-size': 2,\n",
    "    '--epochs': 1,\n",
    "    '--pretrained': None,\n",
    "    '--finetuning': None\n",
    "}\n",
    "\n",
    "est = PyTorch(source_directory=TRAIN_FOLDER_NAME,\n",
    "              entry_script=TRAIN_FILE_NAME,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              node_count=2,\n",
    "              inputs=[file_dataset.as_named_input('hymenoptera_data').as_mount('tmp/dataset')],\n",
    "              distributed_training=Nccl(),\n",
    "              use_gpu=True,\n",
    "              framework_version='1.3',\n",
    "              pip_packages=['azureml-dataprep[pandas,fuse]', 'onnx', 'Pillow==6.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# distributed run with Gloo backend\n",
    "from azureml.train.dnn import PyTorch, Gloo\n",
    "\n",
    "script_params = {\n",
    "    '--dataset-name': 'hymenoptera_data',\n",
    "    '--dist-backend': 'nccl',\n",
    "    '--dist-url': '$AZ_BATCHAI_PYTORCH_INIT_METHOD',\n",
    "    '--rank': '$AZ_BATCHAI_TASK_INDEX',\n",
    "    '--world-size': 2,\n",
    "    '--epochs': 1,\n",
    "    '--pretrained': None,\n",
    "    '--finetuning': None\n",
    "}\n",
    "\n",
    "est = PyTorch(source_directory=TRAIN_FOLDER_NAME,\n",
    "              entry_script=TRAIN_FILE_NAME,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              node_count=2,\n",
    "              inputs=[file_dataset.as_named_input('hymenoptera_data').as_mount('tmp/dataset')],\n",
    "              distributed_training=Gloo(),\n",
    "              use_gpu=True,\n",
    "              framework_version='1.3',\n",
    "              pip_packages=['azureml-dataprep[pandas,fuse]', 'onnx', 'Pillow==6.1'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''              \n",
    "# non distributed run\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--dataset-name': 'hymenoptera_data',\n",
    "    '--world-size': 1,\n",
    "    '--epochs': 1,\n",
    "    '--pretrained': None,\n",
    "    '--finetuning': None\n",
    "}\n",
    "\n",
    "est = PyTorch(source_directory=TRAIN_FOLDER_NAME,\n",
    "              entry_script=TRAIN_FILE_NAME,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              node_count=1,\n",
    "              inputs=[file_dataset.as_named_input('hymenoptera_data').as_mount('tmp/dataset')],\n",
    "              use_gpu=True,\n",
    "              framework_version='1.3',\n",
    "              pip_packages=['azureml-dataprep[pandas,fuse]', 'onnx', 'Pillow==6.1'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Submit the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the estimator to the Azure ML experiment to kick off the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Submit the experiment as a new run.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment%28class%29?view=azure-ml-py#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    '--dataset-name': 'hymenoptera_data',\n",
    "    '--world-size': 1,\n",
    "    '--epochs': 3,\n",
    "    '--pretrained': None,\n",
    "    '--finetuning': None\n",
    "}\n",
    "\n",
    "est = PyTorch(source_directory=TRAIN_FOLDER_NAME,\n",
    "              entry_script=TRAIN_FILE_NAME,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              node_count=1,\n",
    "              inputs=[file_dataset.as_named_input('hymenoptera_data').as_mount('tmp/dataset')],\n",
    "              use_gpu=True,\n",
    "              framework_version='1.3',\n",
    "              pip_packages=['azureml-dataprep[pandas,fuse]', 'onnx', 'Pillow==6.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: ch3-pytorch_sample_1579201450_4cf08a41\n",
      "Web View: https://ml.azure.com/experiments/ch3-pytorch_sample/runs/ch3-pytorch_sample_1579201450_4cf08a41?wsid=/subscriptions/558bd446-4212-46a2-908c-9ab0a628705e/resourcegroups/azure-ml-service-rg/workspaces/myworkspace\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_403fb3fc954b8f0359c8a2778f002909b3b2406f280fa1b18f99cea9a5d6fdea_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-01-16T19:08:42Z Starting output-watcher...\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_1277058ad626755e9c930de601d69a6a\n",
      "Digest: sha256:a149925be774bdfaab213479c81415d69829e89e48e24704a92469d531f789ec\n",
      "Status: Image is up to date for myworkspacreacugrvj.azurecr.io/azureml/azureml_1277058ad626755e9c930de601d69a6a:latest\n",
      "b93201f9420323a4083b3b9c6d7bf58270088956e222f788d5e81179605b5da1\n",
      "2020/01/16 19:08:45 Version: 3.0.01069.0001 Branch: master Commit: 00200ea2\n",
      "2020/01/16 19:08:45 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/01/16 19:08:45 sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_414d63de0a90b0489f9ea1f518f678a6/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_414d63de0a90b0489f9ea1f518f678a6/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: generating new host keys: DSA \n",
      "bash: /azureml-envs/azureml_414d63de0a90b0489f9ea1f518f678a6/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_414d63de0a90b0489f9ea1f518f678a6/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_403fb3fc954b8f0359c8a2778f002909b3b2406f280fa1b18f99cea9a5d6fdea_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "bash: /azureml-envs/azureml_414d63de0a90b0489f9ea1f518f678a6/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job preparation. Current time:2020-01-16T19:08:49.403328\n",
      "Extracting the control code.\n",
      "Creating directory: azureml-logs/\n",
      "Retrieving project from URI: https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml-blobstore-8772624c-5964-4ac6-b73d-42b03c4e019e/azureml/project_zip_32ff164845cf4a7b8ad5af7150e7a2a6?sv=2019-02-02&sr=b&sig=6gUXTeB0h%2BgUmtdJG9ZFBE2y7WxNUfQvXjdNLaNI5GQ%3D&st=2020-01-16T18%3A54%3A12Z&se=2020-01-23T19%3A04%3A12Z&sp=r\n",
      "Download from datastores if requested.\n",
      "Download or mount from datasets if requested.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 79\n",
      "Job preparation is complete. Current time:2020-01-16T19:08:51.731803\n",
      "\n",
      "Streaming azureml-logs/70_driver_log_0.txt\n",
      "==========================================\n",
      "\n",
      "bash: /azureml-envs/azureml_414d63de0a90b0489f9ea1f518f678a6/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Initialize DatasetContextManager.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 137\n",
      "Enter __enter__ of DatasetContextManager\n",
      "Processing 'hymenoptera_data'\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'train_dataset/image_dataset/hymenoptera_data')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"97c6b454-3c1b-48b5-850c-762a252ecfe2\",\n",
      "    \"name\": \"hymenoptera_data\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"hymenoptera training dataset\",\n",
      "    \"workspace\": \"Workspace.create(name='myworkspace', subscription_id='558bd446-4212-46a2-908c-9ab0a628705e', resource_group='azure-ml-service-rg')\"\n",
      "  }\n",
      "}\n",
      "Mounting hymenoptera_data to tmp/dataset\n",
      "Mounted hymenoptera_data to tmp/dataset\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Entering Run History Context Manager.\n",
      "Loaded registered dataset\n",
      "Could not find checkpoint path\n",
      "Namespace(batch_size=32, data_path='tmp/dataset', dataset_name='hymenoptera_data', device='cuda', dist_backend='nccl', dist_url='file:///mnt/batch/tasks/shared/LS_root/jobs/myworkspace/azureml/ch3-pytorch_sample_1579201450_4cf08a41/shared/ch3-pytorch_sample_1579201450_4cf08a41', distributed=True, epochs=1, finetuning=True, lr=0.01, lr_gamma=0.1, lr_step_size=30, model='resnet18', momentum=0.9, output_dir='outputs', pretrained=True, rank=0, resume=None, seed=1, start_epoch=0, test_only=False, weight_decay=0.0001, workers=16, world_size=2)\n",
      "Create output dir and paths\n",
      "Initialize distributed mode\n",
      "Create model\n",
      "Loading model\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "Change model settings\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:137 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.0.5<0>\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:137 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:137 [0] NCCL INFO NET/IB : No device found.\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:137 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.0.5<0>\n",
      "NCCL version 2.4.8+cuda10.1\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO Setting affinity for GPU 0 to 3f\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO NCCL_TREE_THRESHOLD set by environment to 0.\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  PXB\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO Channel 00 :    0   1\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO Channel 01 :    0   1\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO Ring 00 : 1 -> 0 [receive] via NET/Socket/0\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO NET/Socket: Using 1 threads and 1 sockets per thread\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO Ring 00 : 0 -> 1 [send] via NET/Socket/0\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO Ring 01 : 1 -> 0 [receive] via NET/Socket/0\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO NET/Socket: Using 1 threads and 1 sockets per thread\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO Ring 01 : 0 -> 1 [send] via NET/Socket/0\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO Using 128 threads, Min Comp Cap 3, Trees disabled\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:245 [0] NCCL INFO comm 0x7faf40002280 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE\n",
      "ae66cea64d144e1d9811a409c6d7cc6c000001:137:137 [0] NCCL INFO Launch mode Parallel\n",
      "Get relevant model parameters\n",
      "Load data\n",
      "Loading training data\n",
      "Took 3.3720953464508057\n",
      "Loading validation data\n",
      "Creating data sampler\n",
      "Creating criterion\n",
      "Creating optimizer\n",
      "Creating lr scheduler\n",
      "Start training\n",
      "Epoch 0\n",
      "Model in training state\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "[Training] Epoch 0 Acc@1 40.945 Acc@5 90.551 Loss 1.361 Took 2.796283483505249\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_fc1ea8490f55999a87ee57ff3ca6d2c3076f9f786fad32ffa5d41e90ca13d4b5_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "bash: /azureml-envs/azureml_414d63de0a90b0489f9ea1f518f678a6/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: ch3-pytorch_sample_1579201450_4cf08a41\n",
      "Web View: https://ml.azure.com/experiments/ch3-pytorch_sample/runs/ch3-pytorch_sample_1579201450_4cf08a41?wsid=/subscriptions/558bd446-4212-46a2-908c-9ab0a628705e/resourcegroups/azure-ml-service-rg/workspaces/myworkspace\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'ch3-pytorch_sample_1579201450_4cf08a41',\n",
       " 'target': 'gpucluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-01-16T19:08:36.597214Z',\n",
       " 'endTimeUtc': '2020-01-16T19:12:52.608642Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '378d5269-500b-495b-91cb-1c6a1b3dcfb6',\n",
       "  'azureml.git.repository_uri': 'https://github.com/marvinbuss/AzureMLWorkshop',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/marvinbuss/AzureMLWorkshop',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '6c3ded7309c155144572d6c6e72bfaccb70dbc72',\n",
       "  'mlflow.source.git.commit': '6c3ded7309c155144572d6c6e72bfaccb70dbc72',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_1277058ad626755e9c930de601d69a6a',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '97c6b454-3c1b-48b5-850c-762a252ecfe2'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'hymenoptera_data', 'mechanism': 'Mount', 'pathOnCompute': 'tmp/dataset'}}],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'arguments': ['--dataset-name',\n",
       "   'hymenoptera_data',\n",
       "   '--dist-backend',\n",
       "   'nccl',\n",
       "   '--dist-url',\n",
       "   '$AZ_BATCHAI_PYTORCH_INIT_METHOD',\n",
       "   '--rank',\n",
       "   '$AZ_BATCHAI_TASK_INDEX',\n",
       "   '--world-size',\n",
       "   '2',\n",
       "   '--epochs',\n",
       "   '1',\n",
       "   '--pretrained',\n",
       "   '--finetuning'],\n",
       "  'sourceDirectoryDataStore': 'workspaceblobstore',\n",
       "  'framework': 'PyTorch',\n",
       "  'communicator': 'Nccl',\n",
       "  'target': 'gpucluster',\n",
       "  'dataReferences': {'workspaceblobstore': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': None,\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'data': {'hymenoptera_data': {'dataLocation': {'dataset': {'id': '97c6b454-3c1b-48b5-850c-762a252ecfe2'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'hymenoptera_data',\n",
       "    'pathOnCompute': 'tmp/dataset',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 2,\n",
       "  'environment': {'name': 'Experiment ch3-pytorch_sample Environment',\n",
       "   'version': 'Autosave_2020-01-16T08:24:37Z_f32cb9e4',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-dataprep[pandas,fuse]',\n",
       "        'onnx',\n",
       "        'Pillow==6.1',\n",
       "        'azureml-defaults',\n",
       "        'torch==1.3.1',\n",
       "        'torchvision==0.4.1',\n",
       "        'horovod==0.18.1',\n",
       "        'tensorboard==1.14.0',\n",
       "        'future==0.17.1']}],\n",
       "     'name': 'azureml_414d63de0a90b0489f9ea1f518f678a6'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_TREE_THRESHOLD': '0'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 2},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_403fb3fc954b8f0359c8a2778f002909b3b2406f280fa1b18f99cea9a5d6fdea_d.txt': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/azureml-logs/55_azureml-execution-tvmps_403fb3fc954b8f0359c8a2778f002909b3b2406f280fa1b18f99cea9a5d6fdea_d.txt?sv=2019-02-02&sr=b&sig=7qo%2BZoiZqkmVDh2vE6Q%2Bc12w4gcfPUbhlzmHXAMoXWI%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_fc1ea8490f55999a87ee57ff3ca6d2c3076f9f786fad32ffa5d41e90ca13d4b5_d.txt': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/azureml-logs/55_azureml-execution-tvmps_fc1ea8490f55999a87ee57ff3ca6d2c3076f9f786fad32ffa5d41e90ca13d4b5_d.txt?sv=2019-02-02&sr=b&sig=ZIwhnX5B5F%2BhuQWpmuZMDQEzaT1gi4%2FW69ZwnB%2B14sc%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_403fb3fc954b8f0359c8a2778f002909b3b2406f280fa1b18f99cea9a5d6fdea_d.txt': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/azureml-logs/65_job_prep-tvmps_403fb3fc954b8f0359c8a2778f002909b3b2406f280fa1b18f99cea9a5d6fdea_d.txt?sv=2019-02-02&sr=b&sig=VHiUL1J%2FDeVQug36LzR8FpEJEKordqkKbFVmHwUaCn8%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_fc1ea8490f55999a87ee57ff3ca6d2c3076f9f786fad32ffa5d41e90ca13d4b5_d.txt': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/azureml-logs/65_job_prep-tvmps_fc1ea8490f55999a87ee57ff3ca6d2c3076f9f786fad32ffa5d41e90ca13d4b5_d.txt?sv=2019-02-02&sr=b&sig=6JiFK9il577rR5%2BJ0rbaqbIy1J7Hzlp0aFi2anSCeDc%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_0.txt': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=aTdMJ96chSfmG%2FjaLk0daJPJyr2skA6oPxWwHDR6L1c%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_1.txt': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=J563%2FRK7hoB%2FLahnSka81TMPmE7gFrFafcyIPW5ydrc%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_fc1ea8490f55999a87ee57ff3ca6d2c3076f9f786fad32ffa5d41e90ca13d4b5_d.txt': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/azureml-logs/75_job_post-tvmps_fc1ea8490f55999a87ee57ff3ca6d2c3076f9f786fad32ffa5d41e90ca13d4b5_d.txt?sv=2019-02-02&sr=b&sig=wdzti3ijKus1M0PNWeA2KFNzN2p2M206wrDAX2IQxgs%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=UwhJAC2rvAriJcWOo8S1ZMQKqplZjMOYaA%2FDyuqVWJM%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=i9HSiflrM2JOfCmytTjYRi4Hv0nPBts8wLndrFrJXrE%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'logs/azureml/0_137_azureml.log': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/logs/azureml/0_137_azureml.log?sv=2019-02-02&sr=b&sig=jMTt2MYvOBB9FP70YClmKFrgupctLCezFTeT%2BNmsZEI%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'logs/azureml/1_114_azureml.log': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/logs/azureml/1_114_azureml.log?sv=2019-02-02&sr=b&sig=5MuVtJrCS8rUZyRjuYKb3QgnUgBFrcL1Z5C7vYR8PQI%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://myworkspstoragebqrsddbr.blob.core.windows.net/azureml/ExperimentRun/dcid.ch3-pytorch_sample_1579201450_4cf08a41/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=TCzF98tDNtia2obOSGWB9HUNTHNgw81EhXZCSqpVyHI%3D&st=2020-01-16T19%3A02%3A53Z&se=2020-01-17T03%3A12%3A53Z&sp=r'}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(est)\n",
    "run.wait_for_completion(show_output=True, wait_post_processing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a model trained on a remote cluster. Retrieve all the metrics logged during the run, including the accuracy of the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Retrieve the metrics of the run.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run%28class%29?view=azure-ml-py#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register model from run\n",
    "from azureml.core import Model\n",
    "\n",
    "model = run.register_model(model_name='ch3-pytorch-model',\n",
    "                           model_path='outputs/model.onnx',\n",
    "                           model_framework=Model.Framework.ONNX,\n",
    "                           model_framework_version='1.3',\n",
    "                           datasets=[('Training dataset', file_dataset)],\n",
    "                           description='PyTorch hymenoptera classification.',\n",
    "                           tags={'area': 'hymenoptera_data', 'type': 'pytorch'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BROKEN FROM HERE** and no-code Deployment should work again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tune model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen how to do a simple Scikit-learn training run using the SDK, let's see if we can further improve the accuracy of our model. We can optimize our model's hyperparameters using Azure Machine Learning's hyperparameter tuning capabilities.\n",
    "\n",
    "First, we will define the hyperparameter space to sweep over. Let's tune the `kernel` and `penalty` parameters. In this example we will use random sampling to try different configuration sets of hyperparameters to maximize our primary metric, `Accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice, uniform, loguniform\n",
    "from azureml.train.hyperdrive.policy import MedianStoppingPolicy\n",
    "\n",
    "# distributed run with Nccl backend\n",
    "script_params = {\n",
    "    '--dataset-name': 'hymenoptera_data',\n",
    "    '--dist-backend': 'nccl',\n",
    "    '--dist-url': '$AZ_BATCHAI_PYTORCH_INIT_METHOD',\n",
    "    '--rank': '$AZ_BATCHAI_TASK_INDEX',\n",
    "    '--world-size': 2,\n",
    "    '--epochs': 1,\n",
    "    '--pretrained': None,\n",
    "    '--finetuning': None\n",
    "}\n",
    "\n",
    "est = PyTorch(source_directory=TRAIN_FOLDER_NAME,\n",
    "              entry_script=TRAIN_FILE_NAME,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              node_count=2,\n",
    "              inputs=[file_dataset.as_named_input('hymenoptera_data').as_mount('tmp/dataset')],\n",
    "              distributed_training=Nccl(),\n",
    "              use_gpu=True,\n",
    "              framework_version='1.3',\n",
    "              pip_packages=['azureml-dataprep[pandas,fuse]', 'onnx', 'Pillow==6.1'])\n",
    "\n",
    "param_sampling = RandomParameterSampling({\n",
    "    '--lr': loguniform(0.0005, 0.01),\n",
    "    '--momentum': uniform(0.45, 0.55)\n",
    "    })\n",
    "\n",
    "# '--model': choice('resnet18', 'vgg11_bn', 'mobilenet_v2', 'shufflenet_v2_x0_5')\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator=est,\n",
    "                                         hyperparameter_sampling=param_sampling, \n",
    "                                         primary_metric_name='val_acc1_avg',\n",
    "                                         primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                         max_total_runs=2,\n",
    "                                         max_concurrent_runs=2,\n",
    "                                         policy=MedianStoppingPolicy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lauch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Submit the hyperdrive run\n",
    "\n",
    "Hint: Is is very similar to the experiment submission before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: ch3-pytorch_sample_1579209848505614\n",
      "Web View: https://ml.azure.com/experiments/ch3-pytorch_sample/runs/ch3-pytorch_sample_1579209848505614?wsid=/subscriptions/558bd446-4212-46a2-908c-9ab0a628705e/resourcegroups/azure-ml-service-rg/workspaces/myworkspace\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2020-01-16T21:24:10.159580][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.<END>\\n\"\"<START>[2020-01-16T21:24:09.868444][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space<END>\\n\"\"<START>[2020-01-16T21:24:09.371350][API][INFO]Experiment created<END>\\n\"<START>[2020-01-16T21:24:10.7384346Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: ch3-pytorch_sample_1579209848505614\n",
      "Web View: https://ml.azure.com/experiments/ch3-pytorch_sample/runs/ch3-pytorch_sample_1579209848505614?wsid=/subscriptions/558bd446-4212-46a2-908c-9ab0a628705e/resourcegroups/azure-ml-service-rg/workspaces/myworkspace\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n\"Detailed error not set on the Run. Please check the logs for details.\"\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n\\\"Detailed error not set on the Run. Please check the logs for details.\\\"\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-4ce379da33e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhyperdrive_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperdrive_run_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhyperdrive_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwait_post_processing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[0;32m    655\u001b[0m                     \u001b[0mfile_handle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m                     raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    658\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\core\\run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[1;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[0;32m    894\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 896\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m         \u001b[0mfile_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n\"Detailed error not set on the Run. Please check the logs for details.\"\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n\\\"Detailed error not set on the Run. Please check the logs for details.\\\"\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "hyperdrive_run = exp.submit(hyperdrive_run_config)\n",
    "hyperdrive_run.wait_for_completion(show_output=True, wait_post_processing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times, finding the best hyperparameter values for your model can be an iterative process, needing multiple tuning runs that learn from previous hyperparameter tuning runs. Reusing knowledge from these previous runs will accelerate the hyperparameter tuning process, thereby reducing the cost of tuning the model and will potentially improve the primary metric of the resulting model. When warm starting a hyperparameter tuning experiment with Bayesian sampling, trials from the previous run will be used as prior knowledge to intelligently pick new samples, so as to improve the primary metric. Additionally, when using Random or Grid sampling, any early termination decisions will leverage metrics from the previous runs to determine poorly performing training runs. \n",
    "\n",
    "Azure Machine Learning allows you to warm start your hyperparameter tuning run by leveraging knowledge from up to 5 previously completed hyperparameter tuning parent runs. \n",
    "\n",
    "Additionally, there might be occasions when individual training runs of a hyperparameter tuning experiment are cancelled due to budget constraints or fail due to other reasons. It is now possible to resume such individual training runs from the last checkpoint (assuming your training script handles checkpoints). Resuming an individual training run will use the same hyperparameter configuration and mount the storage used for that run. The training script should accept the \"--resume-from\" argument, which contains the checkpoint or model files from which to resume the training run. You can also resume individual runs as part of an experiment that spends additional budget on hyperparameter tuning. Any additional budget, after resuming the specified training runs is used for exploring additional configurations.\n",
    "\n",
    "For more information on warm starting and resuming hyperparameter tuning runs, please refer to the [Hyperparameter Tuning for Azure Machine Learning documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all jobs finish, we can find out the one that has the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Get the best run from the hyperdrive experiment\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriverun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Register model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step in the training script wrote the file `model.pkl` in a directory named `outputs` in the VM of the cluster where the job is executed. `outputs` is a special directory in that all content in this  directory is automatically uploaded to your workspace.  This content appears in the run record in the experiment under your workspace. Hence, the model file is now also available in your workspace.\n",
    "\n",
    "You can see files associated with that run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Get all the file names associated with the best run.\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run%28class%29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the model in the workspace so that you (or other collaborators) can later query, examine, and deploy this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Fill in the missing values below to register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "model = best_run.register_model(model_name='ch3-pytorch-model',\n",
    "                                model_path='outputs/model.onnx',\n",
    "                                model_framework=Model.Framework.ONNX,\n",
    "                                model_framework_version='1.3',\n",
    "                                datasets=[('Training dataset', file_dataset)],\n",
    "                                description='PyTorch hymenoptera classification.',\n",
    "                                tags={'area': 'hymenoptera_data', 'type': 'pytorch'})\n",
    "\n",
    "print(model.name, model.id, model.version, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, your model is ready for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No-code model deployment is currently in preview and supports various frameworks and model types including Tensorflow SavedModel format, ONNX models and Scikit-learn models. No code model deployment is supported for all built-in scikit-learn model types.\n",
    "\n",
    "The deployment will take a few minutes and will take place on an Azure Container Instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Fill in the missing values to deploy the model as a no-code webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service_no_code = Model.deploy(workspace=ws,\n",
    "                               name='ch3-pytorch-service',\n",
    "                               models=[model])\n",
    "service_no_code.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If deployment fails, then retry with:\n",
    "#service_no_code.update(models=[model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Get the logs for the web service\n",
    "\n",
    "Hint: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice%28class%29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#service_no_code.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert this Webservice object into a JSON serialized dictionary, which lists all the details of the webservice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service_no_code.serialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is an example of a Python client that can be used with the container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Fill in the missing part to execute the request against the web service\n",
    "\n",
    "Hint: Look in the same class as for the previous hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "\n",
    "headers = {'Content-Type': 'application/json', 'Accept': 'application/json'}\n",
    "\n",
    "if service_no_code.auth_enabled:\n",
    "    headers['Authorization'] = 'Bearer '+ service_no_code.get_keys()[0]\n",
    "elif service_no_code.token_auth_enabled:\n",
    "    headers['Authorization'] = 'Bearer '+ service_no_code.get_token()[0]\n",
    "\n",
    "scoring_uri = service_no_code.scoring_uri\n",
    "print(scoring_uri)\n",
    "with open(os.path.join('test_deployment', 'onnx-mnist-predict-input.json'), 'rb') as data_file:\n",
    "    response = requests.post(\n",
    "        scoring_uri, data=data_file, headers=headers)\n",
    "print(response.status_code)\n",
    "print(response.elapsed)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the service to save cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_no_code.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
